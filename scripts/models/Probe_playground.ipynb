{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6fc5f6-cbbb-4446-8b3e-dda29abdefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scripts.dataset_creators.read_internal_states import HiddenStatesDataset\n",
    "from scripts.eval.run_token_scoring import score_predictions_labels\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0dfe6ced-2064-4310-aca6-b7ba9700ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:03<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:21<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 17\n"
     ]
    }
   ],
   "source": [
    "#### load data \n",
    "train_folder_path = '/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/GPT_annotated/XSUM/mistral7b/document_context_gpt/'\n",
    "\n",
    "train_data, test_data, class_weights = HiddenStatesDataset().make_data(folder_path, \n",
    "                                                            hidden_state_idx = 32)\n",
    "\n",
    "\n",
    "eval_dir = '/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/Genaudit/XSUM/mistral7b/document_context/'\n",
    "eval_data_1, eval_data_2, _ = HiddenStatesDataset().make_data(eval_dir, \n",
    "                                                            hidden_state_idx = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9eb6fa9-1a57-4716-b731-d25ec0994a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = eval_data_2 + eval_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62181bcf-d26a-4ff1-8468-c3a9bab0b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = '/scratch/ramprasad.sa/probing_summarization_factuality/probes/linear_probe/GPT_annotated/XSUM/mistral7b'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc0b1611-3d6b-457e-a7b1-2bfeffb1a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6077\n",
      "Validation scores {'auc': 0.8207237806555795, 'bacc': 0.3040839524215483}\n",
      "Test scores {'auc': 0.7168457330021956, 'bacc': 0.4215797430083144}\n",
      "Epoch [20/100], Loss: 0.9490\n",
      "Validation scores {'auc': 0.7715711083145014, 'bacc': 0.40677140421385943}\n",
      "Test scores {'auc': 0.6590990893711982, 'bacc': 0.5075585789871504}\n",
      "Epoch [30/100], Loss: 0.0002\n",
      "Validation scores {'auc': 0.7860322873110597, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6605748119353562, 'bacc': 0.5034013605442177}\n",
      "Epoch [40/100], Loss: 0.0001\n",
      "Validation scores {'auc': 0.7860232659891655, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.658559190872116, 'bacc': 0.5034013605442177}\n",
      "Epoch [50/100], Loss: 0.0001\n",
      "Validation scores {'auc': 0.7860322873110597, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6576143684987223, 'bacc': 0.5034013605442177}\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Validation scores {'auc': 0.7860999472252669, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6569664902998237, 'bacc': 0.5034013605442177}\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Validation scores {'auc': 0.7861676071394742, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6563366087175612, 'bacc': 0.5034013605442177}\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Validation scores {'auc': 0.7860954365643197, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6559766763848396, 'bacc': 0.5032753842277652}\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Validation scores {'auc': 0.7860909259033726, 'bacc': 0.4705273413713311}\n",
      "Test scores {'auc': 0.6555627542022101, 'bacc': 0.5032753842277652}\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Validation scores {'auc': 0.7861225005300025, 'bacc': 0.47038525555149596}\n",
      "Test scores {'auc': 0.655319799877623, 'bacc': 0.5032753842277652}\n"
     ]
    }
   ],
   "source": [
    "#### train model and run validation \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple linear probe model\n",
    "class LogisticRegressionProbe(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegressionProbe, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    \n",
    "def run_model(hstate,\n",
    "             model):\n",
    "    hstate, tokens, labels = dat\n",
    "    nonzero_rows_mask = torch.any(hstate != 0, dim=1)\n",
    "    hstate_filtered = hstate[nonzero_rows_mask] \n",
    "    outputs = model(hstate_filtered.float())\n",
    "    \n",
    "    labels = labels[nonzero_rows_mask]\n",
    "    \n",
    "    return outputs, labels\n",
    "\n",
    "def compute_loss(criterion,\n",
    "                 labels,\n",
    "                 outputs,\n",
    "                 class_weights, \n",
    "                 ):\n",
    "    \n",
    "    label_weights = torch.tensor([class_weights[lab.item()] for lab in labels])\n",
    "    loss = criterion(outputs.squeeze(), labels.float()) \n",
    "    loss = loss * label_weights\n",
    "    loss = torch.mean(loss)\n",
    "    \n",
    "    return loss \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "hstate, tok, lab = train_data[0]\n",
    "input_size = hstate.size(1)\n",
    "output_size = 1  \n",
    "model = LogisticRegressionProbe(input_size)\n",
    "\n",
    "# criterion = nn.BCELoss(reduction='none')\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for dat_idx, dat in enumerate(train_data):\n",
    "        outputs, labels = run_model(dat, \n",
    "                            model)\n",
    "        \n",
    "        loss = compute_loss(criterion,\n",
    "                 labels,\n",
    "                 outputs,\n",
    "                 class_weights)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  #\n",
    "    \n",
    "    filename = f'loss_{loss.item():.4f}_epoch{epoch}'\n",
    "    torch.save(model.state_dict(), f'{write_dir}/{filename}')\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for dat_idx, dat in enumerate(test_data):\n",
    "                hstate, tokens, labels = dat\n",
    "                nonzero_rows_mask = torch.any(hstate != 0, dim=1)\n",
    "                labels = labels[nonzero_rows_mask]\n",
    "\n",
    "                outputs, labels = run_model(dat, \n",
    "                                    model)\n",
    "                outputs = outputs.detach().numpy().squeeze()\n",
    "\n",
    "                all_labels += labels.tolist()\n",
    "                all_predictions += outputs.tolist()\n",
    "                                 \n",
    "        scores_dict = compute_scores(all_labels, all_predictions)\n",
    "        print('Validation scores', scores_dict)\n",
    "        \n",
    "        \n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for dat_idx, dat in enumerate(eval_data):\n",
    "                hstate, tokens, labels = dat\n",
    "                nonzero_rows_mask = torch.any(hstate != 0, dim=1)\n",
    "                labels = labels[nonzero_rows_mask]\n",
    "\n",
    "                outputs, labels = run_model(dat, \n",
    "                                    model)\n",
    "                outputs = outputs.detach().numpy().squeeze()\n",
    "\n",
    "                all_labels += labels.tolist()\n",
    "                all_predictions += outputs.tolist()\n",
    "                                 \n",
    "        scores_dict = compute_scores(all_labels, all_predictions)\n",
    "        print('Test scores', scores_dict)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "887bc9d1-bf22-4d75-a204-6d40b7b0a8de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels[nonzero_rows_mask]\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m run_model(dat, \n\u001b[1;32m     19\u001b[0m                     model)\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     22\u001b[0m all_labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     23\u001b[0m all_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "#### inference code \n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "def compute_scores(labels, predictions):\n",
    "    auc_score = roc_auc_score(labels, predictions)\n",
    "    predictions_binary = [0 if each > 0.5 else 1 for each in predictions]\n",
    "    bacc_score = balanced_accuracy_score(labels, predictions_binary)\n",
    "    return {'auc': auc_score, 'bacc': bacc_score}\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for dat_idx, dat in enumerate(test_data):\n",
    "        hstate, tokens, labels = dat\n",
    "        nonzero_rows_mask = torch.any(hstate != 0, dim=1)\n",
    "        labels = labels[nonzero_rows_mask]\n",
    "        \n",
    "        outputs = run_model(dat, \n",
    "                            model)\n",
    "        outputs = outputs.detach().numpy().squeeze()\n",
    "        \n",
    "        all_labels += labels.tolist()\n",
    "        all_predictions += outputs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38fa0472-4702-4052-ab33-8f017976b93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7797624685945231, 'bacc': 0.462448747614988}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_scores(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfacd966-1922-48f1-9311-c69720e6e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1306c3f-0c52-45c0-8d23-31f9f84824d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "021fba79-6c3a-4d39-9ffb-3fda91b027aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 222864.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(0, num_epochs)):\n",
    "    dat_idx = epoch%len(train_data)\n",
    "    print(dat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d425ce-4316-40f7-8f1f-f0c79e370a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (probe)",
   "language": "python",
   "name": "probe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
