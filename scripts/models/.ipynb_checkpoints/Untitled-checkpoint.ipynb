{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a19c5a4a-88c8-428c-a838-e21de5abbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scripts.dataset_creators.read_internal_states import HiddenStatesDataset\n",
    "from scripts.eval.run_token_scoring import score_predictions_labels\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c0bc4a-65ac-4993-9c18-176c75899b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_files(folder_path,\n",
    "#                  model):\n",
    "#     files = os.listdir(folder_path)\n",
    "#     files = sorted(files)\n",
    "#     print('Total files', len(files))\n",
    "#     for file_name in tqdm(files):\n",
    "#         docid = file_name.split('.pt')[0]\n",
    "#         if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "#             example = torch.load(os.path.join(folder_path, file_name))\n",
    "#             return example\n",
    "\n",
    "model_path = {'mistral7b': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "             'falcon7b': 'tiiuae/falcon-7b-instruct',\n",
    "              'llama7b': '/work/frink/models/Llama-2-7b-chat-hf',\n",
    "             'flanul2': 'google/flan-ul2'}\n",
    "\n",
    "def load_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path[model_name],\n",
    "                                         cache_dir = '/scratch/ramprasad.sa/huggingface_models')\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bed8bcb-234e-4778-8e7b-94aa1204adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer('mistral7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f643b60a-7d5e-4902-9903-9194682c73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:02<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 63\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/GPT_annotated/XSUM/mistral7b/document_context_gpt/'\n",
    "\n",
    "# example = read_files(folder_path, model = 'mistral7b')\n",
    "\n",
    "hs_dataset = HiddenStatesDataset()\n",
    "train_data, test_data, class_weights = hs_dataset.make_data(folder_path, \n",
    "                                                            hidden_state_idx = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f011b6-19f7-44c6-a8d8-f7cf78c95995",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = test_data[0][1]\n",
    "tokens = tokens[tokens != -1]\n",
    "\n",
    "labels = test_data[0][2]\n",
    "labels = np.array(labels[labels != -1])\n",
    "\n",
    "predictions = np.random.randint(2, size=(labels.shape[-1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38643163-10c8-4cbc-ac6f-69c681fdbf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramprasad.sa/.conda/envs/probe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/ramprasad.sa/.conda/envs/probe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/ramprasad.sa/.conda/envs/probe/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "scores = score_predictions_labels(tokens,\n",
    "                                        predictions, \n",
    "                                        labels, \n",
    "                                        model_name = 'mistral7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1362740-a7b1-4e5c-998f-b69077729fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_balanced_acc(scores_maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8c3e4f-f845-4e51-9767-661cae56f3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0923\n",
      "Epoch [200/1000], Loss: 0.0601\n",
      "Epoch [300/1000], Loss: 0.0404\n",
      "Epoch [400/1000], Loss: 0.0271\n",
      "Epoch [500/1000], Loss: 0.0182\n",
      "Epoch [600/1000], Loss: 0.0123\n",
      "Epoch [700/1000], Loss: 0.0082\n",
      "Epoch [800/1000], Loss: 0.0055\n",
      "Epoch [900/1000], Loss: 0.0037\n",
      "Epoch [1000/1000], Loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example hidden state of the model (you need to replace this with your actual hidden state)\n",
    "hidden_state = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Example target labels (you need to replace this with your actual target labels)\n",
    "target_labels = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Define a simple linear probe model\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearProbe, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize the linear probe model\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent optimizer\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(hidden_state.float())  # Forward pass through the model\n",
    "    loss = criterion(outputs.squeeze(), target_labels.float())  # Calculate the loss\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can use the model to make predictions on new data\n",
    "# For example, if you have a new hidden state `new_hidden_state`, you can predict its label as follows:\n",
    "# predicted_labels = model(new_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0924287b-efab-4b2f-924b-7b8fb22f9c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([475, 4096])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60c543c-9c18-4955-bcdf-f4f233613f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-03, 0.0000e+00],\n",
      "        [4.0000e+00, 5.0000e+00, 6.0000e+00]])\n",
      "\n",
      "Tensor after removing rows with all zeros:\n",
      "tensor([[1.0000e+00, 2.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 1.0000e-03, 0.0000e+00],\n",
      "        [4.0000e+00, 5.0000e+00, 6.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with rows containing zeros\n",
    "tensor = torch.tensor([[0, 0, 0], [1, 2, 3], [0, 0.001, 0], [4, 5, 6]])\n",
    "\n",
    "# Find rows with all zeros\n",
    "nonzero_rows_mask = torch.any(tensor != 0, dim=1)\n",
    "\n",
    "# Extract rows that are not all zeros\n",
    "tensor_filtered = tensor[nonzero_rows_mask]\n",
    "\n",
    "print(\"Original Tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "print(\"\\nTensor after removing rows with all zeros:\")\n",
    "print(tensor_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31abd7a9-8430-4287-912a-1eeb37fe0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define a simple linear probe model\n",
    "class LogisticRegressionProbe(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegressionProbe, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "input_size = train_data[0][0].size(1)  # Size of hidden state vector\n",
    "output_size = 1  # Number of target labels\n",
    "model = LogisticRegressionProbe(input_size)\n",
    "\n",
    "\n",
    "# criterion = nn.BCELoss(reduction='none')\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for hstate, tokens, labels in train_data:\n",
    "    nonzero_rows_mask = torch.any(hstate != 0, dim=1)\n",
    "    hstate_filtered = hstate[nonzero_rows_mask] \n",
    "    labels = labels[nonzero_rows_mask]\n",
    "    \n",
    "    outputs = model(hstate_filtered.float())\n",
    "    \n",
    "    \n",
    "    loss = criterion(outputs.squeeze(), labels.float()) \n",
    "    label_weights = torch.tensor([class_weights[lab.item()] for lab in labels])\n",
    "    # print(loss)\n",
    "    loss = loss * label_weights\n",
    "    loss = torch.mean(loss)\n",
    "    \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    # print(loss)\n",
    "    # print(nonzero_rows_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "72ef24a9-30be-4aac-8813-259403a801c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4397e-22, 3.8973e-17, 1.0030e-26, 1.2079e-29, 1.8253e-31, 3.7038e-31,\n",
       "        6.6902e-28, 3.2480e-20, 1.3238e-19, 2.8513e-22, 1.0804e-15, 6.5163e-27,\n",
       "        4.2227e-30, 4.5081e-21, 2.8301e-09, 5.5761e-29, 3.0801e-33, 1.2524e-23,\n",
       "        9.3917e-19, 6.0411e-18, 7.8632e-24, 5.2914e-29, 5.4321e-27, 1.5941e-24,\n",
       "        1.4144e-32, 3.3256e-23, 3.4188e-19, 6.1297e-30, 6.3060e-20, 1.1206e-22,\n",
       "        1.5048e-20, 5.3090e-34, 5.8461e-31, 1.6748e-36, 3.5627e-28, 6.8082e-27,\n",
       "        5.9422e-36, 5.1018e-31, 6.4417e-20, 0.0000e+00, 5.0389e-30, 1.1582e-33,\n",
       "        1.5860e-30, 4.3452e-29, 1.7560e-28, 7.7704e-36, 8.7560e-23, 1.3604e-26,\n",
       "        4.7499e-16, 2.4461e-27, 2.9226e-25, 3.6597e-39, 1.0224e-31, 6.3015e-24,\n",
       "        3.4194e-34, 4.6685e-27, 1.9587e-22, 9.5747e-26, 2.2822e-26, 2.0591e-29,\n",
       "        6.8886e-37, 2.4361e-34, 7.3455e-25, 7.3777e-29, 3.4738e-20, 8.1321e-19,\n",
       "        6.8761e-36, 4.1265e-30], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "212f8230-77fe-459b-9843-04c4fa3943bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "21a7f9a2-64a5-491c-af5b-ab15b8fd5841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270,\n",
       "        0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270,\n",
       "        0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270,\n",
       "        0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270,\n",
       "        0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270,\n",
       "        0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 0.6270, 2.4688, 2.4688,\n",
       "        2.4688, 2.4688, 2.4688, 2.4688, 2.4688, 2.4688, 2.4688, 2.4688, 2.4688,\n",
       "        2.4688, 2.4688, 0.6270, 0.6270, 0.6270])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2007897-6625-40f3-995f-a785c9b32fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (probe)",
   "language": "python",
   "name": "probe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
