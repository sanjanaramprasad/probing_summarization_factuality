{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb43cf2-c7b3-4a0c-ba99-91002d835dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from nnsight import LanguageModel, util\n",
    "from nnsight.tracing.Proxy import Proxy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from scripts.models.prompt_processor import PromptProcessor\n",
    "from scripts.utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8743b32d-902d-418a-bba5-2b366a55038b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>annotated_spans</th>\n",
       "      <th>model</th>\n",
       "      <th>origin</th>\n",
       "      <th>docid_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rachel Usher#REDDIT-83:flanul2-ul2</td>\n",
       "      <td>both me and my girlfriend participate in winte...</td>\n",
       "      <td>I waited outside the locker rooms for my girlf...</td>\n",
       "      <td>nobody</td>\n",
       "      <td>flanul2</td>\n",
       "      <td>REDDIT</td>\n",
       "      <td>REDDIT-83:flanul2-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rachel Usher#REDDIT-83:llama70b-ul2</td>\n",
       "      <td>both me and my girlfriend participate in winte...</td>\n",
       "      <td>A high school student was waiting for his girl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>llama70b</td>\n",
       "      <td>REDDIT</td>\n",
       "      <td>REDDIT-83:llama70b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Rachel Usher#REDDIT-83:falcon7b-ul2</td>\n",
       "      <td>both me and my girlfriend participate in winte...</td>\n",
       "      <td>The protagonist is concerned about a potential...</td>\n",
       "      <td>concerned about a potential delay in meeting&lt;s...</td>\n",
       "      <td>falcon7b</td>\n",
       "      <td>REDDIT</td>\n",
       "      <td>REDDIT-83:falcon7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rachel Usher#REDDIT-83:llama7b-ul2</td>\n",
       "      <td>both me and my girlfriend participate in winte...</td>\n",
       "      <td>The writer and their girlfriend are both invol...</td>\n",
       "      <td>is late&lt;sep&gt;bus and doesn't realize that their...</td>\n",
       "      <td>llama7b</td>\n",
       "      <td>REDDIT</td>\n",
       "      <td>REDDIT-83:llama7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rachel Usher#REDDIT-83:mistral7b-ul2</td>\n",
       "      <td>both me and my girlfriend participate in winte...</td>\n",
       "      <td>The document describes the experience of a hig...</td>\n",
       "      <td>participates&lt;sep&gt;with their girlfriend&lt;sep&gt;ends</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>REDDIT</td>\n",
       "      <td>REDDIT-83:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    id  \\\n",
       "0           0    Rachel Usher#REDDIT-83:flanul2-ul2   \n",
       "1           1   Rachel Usher#REDDIT-83:llama70b-ul2   \n",
       "2           2   Rachel Usher#REDDIT-83:falcon7b-ul2   \n",
       "3           3    Rachel Usher#REDDIT-83:llama7b-ul2   \n",
       "4           4  Rachel Usher#REDDIT-83:mistral7b-ul2   \n",
       "\n",
       "                                              source  \\\n",
       "0  both me and my girlfriend participate in winte...   \n",
       "1  both me and my girlfriend participate in winte...   \n",
       "2  both me and my girlfriend participate in winte...   \n",
       "3  both me and my girlfriend participate in winte...   \n",
       "4  both me and my girlfriend participate in winte...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  I waited outside the locker rooms for my girlf...   \n",
       "1  A high school student was waiting for his girl...   \n",
       "2  The protagonist is concerned about a potential...   \n",
       "3  The writer and their girlfriend are both invol...   \n",
       "4  The document describes the experience of a hig...   \n",
       "\n",
       "                                     annotated_spans      model  origin  \\\n",
       "0                                             nobody    flanul2  REDDIT   \n",
       "1                                                NaN   llama70b  REDDIT   \n",
       "2  concerned about a potential delay in meeting<s...   falcon7b  REDDIT   \n",
       "3  is late<sep>bus and doesn't realize that their...    llama7b  REDDIT   \n",
       "4    participates<sep>with their girlfriend<sep>ends  mistral7b  REDDIT   \n",
       "\n",
       "           docid_processed  \n",
       "0    REDDIT-83:flanul2-ul2  \n",
       "1   REDDIT-83:llama70b-ul2  \n",
       "2   REDDIT-83:falcon7b-ul2  \n",
       "3    REDDIT-83:llama7b-ul2  \n",
       "4  REDDIT-83:mistral7b-ul2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genaudit  = pd.read_csv('/home/ramprasad.sa/probing_summarization_factuality/datasets/Genaudit_annotations.csv')\n",
    "df_genaudit['docid_processed'] = [row['id'].split('#')[-1] for idx, row in df_genaudit.iterrows()]\n",
    "df_genaudit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5706346-4c28-4ae6-a436-6b54fd73f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nnsight_model_wrapper(model_name):\n",
    "    tokenizer, mistral_model = load_model(model_name)\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model = LanguageModel(mistral_model, tokenizer=tokenizer, device_map=\"auto\", dispatch=True)\n",
    "    return tokenizer, model\n",
    "\n",
    "class MakeDataAIE:\n",
    "\n",
    "    def __init__(self,\n",
    "                model_name,\n",
    "                prompt_template,\n",
    "                prompt_template_path,\n",
    "                prompt_type\n",
    "                 ):\n",
    "        \n",
    "        self.tokenizer, self.model = get_nnsight_model_wrapper(model_name)\n",
    "\n",
    "        self.prompt_processor  = PromptProcessor(prompt_template = prompt_template,\n",
    "                                   prompt_template_path = prompt_template_path,\n",
    "                                   prompt_type = prompt_type,\n",
    "                                   tokenizer = self.tokenizer\n",
    "                                  )\n",
    "        \n",
    "    def get_indirect_effect(self,\n",
    "                            prompt_dict):\n",
    "\n",
    "        with self.model.trace() as tracer:\n",
    "            with tracer.invoke(prompt_dict['prompt']) as invoker:\n",
    "                clean_tokens = self.model.input[1][\"input_ids\"].squeeze().save()\n",
    "\n",
    "        \n",
    "        prompt = prompt_dict['prompt']\n",
    "        N_LAYERS = len(self.model.model.layers)\n",
    "        summary_labels = prompt_dict['summary_labels']\n",
    "        summary_tokens = clean_tokens[prompt_dict['instr_prefix_src_suffix_idx']:]\n",
    "        corruption_idx = [i for i in range(prompt_dict['instr_idx'])]\n",
    "        assert(summary_tokens.shape[-1] == len(summary_labels))\n",
    "\n",
    "        corrupted_prompt = self.corrupt_prompt(prompt_tokens = clean_tokens,\n",
    "                                               corruption_idx = corruption_idx)\n",
    "\n",
    "        clean_input_embeddings, clean_hs, clean_logits = self.get_clean_logits( prompt = prompt)\n",
    "\n",
    "        '''noising all tokens of the instructon'''\n",
    "        noised_embeddings, corrupted_hs, corrupted_logits = self.get_corrupted_logits(corrupted_prompt=corrupted_prompt)\n",
    "\n",
    "        summary_token_patching_results = []\n",
    "        summ_idx = 0\n",
    "        for tidx, tgt_token in enumerate(clean_tokens):\n",
    "                ''' after instr, prefix, src, suffix is summary tokens'''\n",
    "                if tidx >= prompt_dict['instr_prefix_src_suffix_idx']:\n",
    "                    assert(tgt_token == summary_tokens[summ_idx])\n",
    "                    \n",
    "\n",
    "                    layer_wise_patching_results = []\n",
    "                    ''' iterate all layers'''\n",
    "                    for layer_idx in range(len(self.model.model.layers)):\n",
    "                            \n",
    "                            _, patched_hs, patched_logits =  self.get_patched_logits(corrupted_prompt = corrupted_prompt,\n",
    "                                                                            clean_hs = clean_hs,\n",
    "                                                                            layer_idx = layer_idx,\n",
    "                                                                            token_idx = tidx - 1)\n",
    "                            \n",
    "                            #### check if while predicting tgt token the corrupted runs layer is not same as pattched run layer\n",
    "                            assert( not torch.allclose(corrupted_hs[layer_idx][:, tidx - 1, :], patched_hs[layer_idx][:, tidx - 1, :]))\n",
    "\n",
    "                            #### check if while predicting tgt token the clean runs layer is same as pattched run layer\n",
    "                            assert(  torch.allclose(clean_hs[layer_idx][:, tidx - 1, :], patched_hs[layer_idx][:, tidx - 1, :]))\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            append_dict = {\n",
    "                                'layer': layer_idx,\n",
    "                                'target': tgt_token.item(),\n",
    "                                'predicted': torch.argmax(clean_logits[tidx - 1]).item(),\n",
    "                                'factual_label': summary_labels[summ_idx],\n",
    "                                'prob_clean': clean_logits[tidx - 1][tgt_token].item(),\n",
    "                                'prob_corrupted': corrupted_logits[tidx - 1][tgt_token].item(),\n",
    "                                'prob_patched': patched_logits[tidx - 1][tgt_token].item()\n",
    "                            }\n",
    "                            layer_wise_patching_results.append(append_dict)\n",
    "                        \n",
    "\n",
    "                    summary_token_patching_results.append(layer_wise_patching_results)\n",
    "                    summ_idx += 1\n",
    "\n",
    "        return summary_token_patching_results\n",
    "        \n",
    "    def get_layerwise_causal_analysis(self,\n",
    "                                      df,\n",
    "                                      write_path):\n",
    "            \n",
    "            for idx, row in tqdm(df[~df['annotated_spans'].isnull()].iterrows(), total = len(df[~df['annotated_spans'].isnull()])):\n",
    "                uid = row['id']\n",
    "                uid = '_'.join(uid.split())\n",
    "                source = row['source']\n",
    "                summary = row['summary']\n",
    "                nonfactual_spans = row['annotated_spans']\n",
    "                prompt_dict = self.prompt_processor.make_prompt_token_labels(source= source,\n",
    "                                                                        summary = summary,\n",
    "                                                                        nonfactual_spans = nonfactual_spans)\n",
    "                print(prompt_dict)\n",
    "                # summary_patching_results = self.get_indirect_effect(prompt_dict= prompt_dict)\n",
    "                # filename = f'{write_path}/{uid}.jsonl'\n",
    "                # self.write_patched_results(summary_patching_results = summary_patching_results,\n",
    "                #                            write_path = filename)\n",
    "                return prompt_dict\n",
    "\n",
    "            # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbaa30c-8f2c-4c15-b9aa-55a5f38e650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramprasad.sa/.conda/envs/probe/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bcc38b1df146e59fd41c4f6a0c2e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template_path = '/home/ramprasad.sa/probing_summarization_factuality/datasets/prompt_templates/'\n",
    "prompt_type = 'document_context'\n",
    "prompt_template = f'{{instruction}}{{prompt_prefix}}{{source}}{{prompt_suffix}}{{summary}}'\n",
    "model_name = 'mistral7b' \n",
    "origin = 'XSUM'\n",
    "\n",
    "df_filtered = df_genaudit[(df_genaudit['model'] == model_name) & (df_genaudit['origin'] == origin)]\n",
    "\n",
    "nnsight_patcher = MakeDataAIE(model_name = model_name,\n",
    "                prompt_template = prompt_template,\n",
    "                prompt_template_path = prompt_template_path,\n",
    "                prompt_type = prompt_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235b040d-faab-4f05-8623-7140376371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>annotated_spans</th>\n",
       "      <th>model</th>\n",
       "      <th>origin</th>\n",
       "      <th>docid_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>Cynthia Lamanda#XSUM-35862185:mistral7b-ul2</td>\n",
       "      <td>England failed to build on the optimism genera...</td>\n",
       "      <td>The document discusses England's loss to the N...</td>\n",
       "      <td>in London&lt;sep&gt;the winner</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-35862185:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>Cynthia Lamanda#XSUM-34846955:mistral7b-ul2</td>\n",
       "      <td>Welsh housing associations directly contribute...</td>\n",
       "      <td>Welsh housing associations made a significant ...</td>\n",
       "      <td>£1.1</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-34846955:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>Rachel Usher#XSUM-34007864:mistral7b-ul2</td>\n",
       "      <td>The results have been published for more than ...</td>\n",
       "      <td>The GCSE results have been published, showing ...</td>\n",
       "      <td>GC</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-34007864:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>Cynthia Lamanda#XSUM-37820092:mistral7b-ul2</td>\n",
       "      <td>Shanghai is trialling a unisex public toilet b...</td>\n",
       "      <td>Shanghai is trialting a unisex public toilet b...</td>\n",
       "      <td>trialting</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-37820092:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>Cynthia Lamanda#XSUM-19389161:mistral7b-ul2</td>\n",
       "      <td>Indian Olympics bronze medallist, boxer MC Mar...</td>\n",
       "      <td>Bollywood director Sanjay Leela Bhansali plans...</td>\n",
       "      <td>with Mary Kom herself&lt;sep&gt;leadership</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-19389161:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>Rachel Usher#XSUM-38021627:mistral7b-ul2</td>\n",
       "      <td>In the Scottish Football Association's stateme...</td>\n",
       "      <td>The Scottish Football Association (SFA) made a...</td>\n",
       "      <td>regarding&lt;sep&gt;resignation&lt;sep&gt;finding replacem...</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-38021627:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>Cynthia Lamanda#XSUM-31763768:mistral7b-ul2</td>\n",
       "      <td>Bestival has revealed an all-female line-up in...</td>\n",
       "      <td>Bestival has announced an all-female line-up f...</td>\n",
       "      <td>male</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-31763768:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>Rachel Usher#XSUM-35643091:mistral7b-ul2</td>\n",
       "      <td>At Harper Adams University they are fitting tr...</td>\n",
       "      <td>Harper Adams University is conducting research...</td>\n",
       "      <td>and habitat</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-35643091:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>694</td>\n",
       "      <td>Rachel Usher#XSUM-39387550:mistral7b-ul2</td>\n",
       "      <td>US President Donald Trump has withdrawn his he...</td>\n",
       "      <td>The American Health Care Act, a healthcare bil...</td>\n",
       "      <td>and the Republican Party</td>\n",
       "      <td>mistral7b</td>\n",
       "      <td>XSUM</td>\n",
       "      <td>XSUM-39387550:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           id  \\\n",
       "112         112  Cynthia Lamanda#XSUM-35862185:mistral7b-ul2   \n",
       "373         373  Cynthia Lamanda#XSUM-34846955:mistral7b-ul2   \n",
       "404         404     Rachel Usher#XSUM-34007864:mistral7b-ul2   \n",
       "416         416  Cynthia Lamanda#XSUM-37820092:mistral7b-ul2   \n",
       "500         500  Cynthia Lamanda#XSUM-19389161:mistral7b-ul2   \n",
       "533         533     Rachel Usher#XSUM-38021627:mistral7b-ul2   \n",
       "579         579  Cynthia Lamanda#XSUM-31763768:mistral7b-ul2   \n",
       "688         688     Rachel Usher#XSUM-35643091:mistral7b-ul2   \n",
       "694         694     Rachel Usher#XSUM-39387550:mistral7b-ul2   \n",
       "\n",
       "                                                source  \\\n",
       "112  England failed to build on the optimism genera...   \n",
       "373  Welsh housing associations directly contribute...   \n",
       "404  The results have been published for more than ...   \n",
       "416  Shanghai is trialling a unisex public toilet b...   \n",
       "500  Indian Olympics bronze medallist, boxer MC Mar...   \n",
       "533  In the Scottish Football Association's stateme...   \n",
       "579  Bestival has revealed an all-female line-up in...   \n",
       "688  At Harper Adams University they are fitting tr...   \n",
       "694  US President Donald Trump has withdrawn his he...   \n",
       "\n",
       "                                               summary  \\\n",
       "112  The document discusses England's loss to the N...   \n",
       "373  Welsh housing associations made a significant ...   \n",
       "404  The GCSE results have been published, showing ...   \n",
       "416  Shanghai is trialting a unisex public toilet b...   \n",
       "500  Bollywood director Sanjay Leela Bhansali plans...   \n",
       "533  The Scottish Football Association (SFA) made a...   \n",
       "579  Bestival has announced an all-female line-up f...   \n",
       "688  Harper Adams University is conducting research...   \n",
       "694  The American Health Care Act, a healthcare bil...   \n",
       "\n",
       "                                       annotated_spans      model origin  \\\n",
       "112                           in London<sep>the winner  mistral7b   XSUM   \n",
       "373                                               £1.1  mistral7b   XSUM   \n",
       "404                                                 GC  mistral7b   XSUM   \n",
       "416                                          trialting  mistral7b   XSUM   \n",
       "500               with Mary Kom herself<sep>leadership  mistral7b   XSUM   \n",
       "533  regarding<sep>resignation<sep>finding replacem...  mistral7b   XSUM   \n",
       "579                                               male  mistral7b   XSUM   \n",
       "688                                        and habitat  mistral7b   XSUM   \n",
       "694                           and the Republican Party  mistral7b   XSUM   \n",
       "\n",
       "                 docid_processed  \n",
       "112  XSUM-35862185:mistral7b-ul2  \n",
       "373  XSUM-34846955:mistral7b-ul2  \n",
       "404  XSUM-34007864:mistral7b-ul2  \n",
       "416  XSUM-37820092:mistral7b-ul2  \n",
       "500  XSUM-19389161:mistral7b-ul2  \n",
       "533  XSUM-38021627:mistral7b-ul2  \n",
       "579  XSUM-31763768:mistral7b-ul2  \n",
       "688  XSUM-35643091:mistral7b-ul2  \n",
       "694  XSUM-39387550:mistral7b-ul2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[~df_filtered['annotated_spans'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcf4572-2517-466d-a608-df4b1c8d9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                     | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attri 257\n",
      "0\n",
      "100\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                     | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': \"Generate a summary for the following document in brief. When creating the summary, only use information that is present in the documentGenerate a summary for the following document in brief. When creating the summary, only use information that is present in the document CONTENT:England failed to build on the optimism generated by their thrilling victory in Germany as they were beaten in a friendly by the Netherlands, who have not even qualified for Euro 2016.. On a night when Wembley paid its respects to the late Dutch legend Johan Cruyff with applause in SUMMARY:The document discusses England's loss to the Netherlands in a friendly football match, which took place at Wembley Stadium in London.. Despite an impressive victory over Germany in their previous friendly, England failed to build on their momentum and lost 2-1 to the Netherlands.. Jamie Vardy, the man-of-the-match, scored England's goal with a slick passing move that led to a cross from Kyle Walker, but England's defence was unable to protect their lead.. Danny Rose was punished for a sloppy pass that led to a penalty, and Vincent Janssen scored the winner from the spot.\", 'instruction': 'Generate a summary for the following document in brief. When creating the summary, only use information that is present in the document', 'prompt_prefix': 'Generate a summary for the following document in brief. When creating the summary, only use information that is present in the document CONTENT:', 'source_doc': 'England failed to build on the optimism generated by their thrilling victory in Germany as they were beaten in a friendly by the Netherlands, who have not even qualified for Euro 2016.. On a night when Wembley paid its respects to the late Dutch legend Johan Cruyff with applause in', 'summary': 'summary', 'prompt_template': '{instruction}{prompt_prefix}{source}{prompt_suffix}{summary}', 'prompt_suffix': ' SUMMARY:', 'instr_idx': 25, 'instr_prefix_idx': 53, 'instr_prefix_src_idx': 120, 'instr_prefix_src_suffix_idx': 125, 'summary_labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_dict = nnsight_patcher.get_layerwise_causal_analysis(df_filtered,\n",
    "                                             write_path = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5789e33-16cb-4ae1-9bf5-3ce624f8d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens = nnsight_patcher.tokenizer(prompt_dict['prompt'])\n",
    "clean_tokens = prompt_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72858714-8134-4eab-8c38-4c3a313fd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = prompt_dict['prompt_template']\n",
    "prompt_prefix = prompt_dict['prompt_template']\n",
    "prompt_suffix = prompt_dict['prompt_template']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3888e70-2334-41c3-adf0-afbb23288b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses England's loss to the Netherlands in a friendly football match, which took place at Wembley Stadium in London.. Despite an impressive victory over Germany in their previous friendly, England failed to build on their momentum and lost 2-1 to the Netherlands.. Jamie Vardy, the man-of-the-match, scored England's goal with a slick passing move that led to a cross from Kyle Walker, but England's defence was unable to protect their lead.. Danny Rose was punished for a sloppy pass that led to a penalty, and Vincent Janssen scored the winner from the spot. summary\n",
      "DIFF in masked {',', 'an', 'and', 'but', 'a', '.', \"'s\", '..', 'Despite', 'the', 'The', '-'}\n"
     ]
    }
   ],
   "source": [
    "from scripts.dataset_creators.coco_mask import Coco\n",
    "\n",
    "coco_class = Coco()\n",
    "\n",
    "prompt = prompt_dict['prompt']\n",
    "N_LAYERS = len(nnsight_patcher.model.model.layers)\n",
    "summary_labels = prompt_dict['summary_labels']\n",
    "summary_tokens = clean_tokens[prompt_dict['instr_prefix_src_suffix_idx']:]\n",
    "corruption_idx = [i for i in range(prompt_dict['instr_idx'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "#### corrupt prompt of idx - 1 \n",
    "# summary = nnsight_patcher.tokenizer.decode(summary_tokens)\n",
    "print(nnsight_patcher.tokenizer.decode(summary_tokens),prompt_dict['summary'])\n",
    "            \n",
    "summary_keywords = coco_class.get_masked_token_list(summary)\n",
    "# summary_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d2b529e-41d2-4fe9-b459-efa24559f6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 583], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token = '_'\n",
    "nnsight_patcher.tokenizer(mask_token)\n",
    "# prompt_dict['prompt'], prompt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf0e93ea-9dc9-4323-bc09-dd9562eef7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corrupt_token = nnsight_patcher.tokenizer('_').input_ids[1:][0]\n",
    "\n",
    "summ_idx = 0\n",
    "for tidx, tgt_token in enumerate(clean_tokens):\n",
    "    ''' after instr, prefix, src, suffix is summary tokens'''\n",
    "    if tidx >= prompt_dict['instr_prefix_src_suffix_idx']:\n",
    "        assert(tgt_token == summary_tokens[summ_idx])\n",
    "        tgt_token_str = nnsight_patcher.tokenizer.decode(tgt_token)\n",
    "        # corrupted_idx = tidx - 1\n",
    "        # corrupt_summary_tokens = clean_tokens[:corrupted_idx] + [corrupt_token] + clean_tokens[corrupted_idx + 1:]\n",
    "        # print(nnsight_patcher.tokenizer.decode(corrupt_summary_tokens), nnsight_patcher.tokenizer.decode(tgt_token))\n",
    "        summ_idx += 1\n",
    "    \n",
    "        keywords_i = []\n",
    "        if tgt_token_str and len(tgt_token_str) > 1:\n",
    "            keywords_i = list(set([each for each in summary_keywords if each.startswith(tgt_token_str)]))\n",
    "            \n",
    "            masked_document = coco_class.mask_document(source_doc = prompt_dict['source_doc'], \n",
    "                                                      masked_token_list = keywords_i, \n",
    "                                                      mask_token = mask_token,\n",
    "                                                      mask_strategy ='span')\n",
    "            if masked_document != prompt_dict['source_doc']:\n",
    "                # print(tidx, tgt_token_str, keywords_i, masked_document)\n",
    "                new_prompt  = prompt_template.format(instruction = prompt_dict['instruction'],\n",
    "                                                     prompt_prefix = prompt_dict['prompt_prefix'],\n",
    "                                                     source = masked_document,\n",
    "                                                     prompt_suffix = prompt_dict['prompt_suffix'],\n",
    "                                                    summary = summary\n",
    "                                                    )\n",
    "                # print(new_prompt)\n",
    "            # new_prompt = \n",
    "        # print('***'* 13)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87c4b1cc-8ac2-4ec1-85fa-1fed1160b509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document',\n",
       " 'discusses',\n",
       " 'England',\n",
       " 'loss',\n",
       " 'to',\n",
       " 'Netherlands',\n",
       " 'in',\n",
       " 'friendly',\n",
       " 'football',\n",
       " 'match',\n",
       " 'which',\n",
       " 'took',\n",
       " 'place',\n",
       " 'at',\n",
       " 'Wembley',\n",
       " 'Stadium',\n",
       " 'in',\n",
       " 'London',\n",
       " 'impressive',\n",
       " 'victory',\n",
       " 'over',\n",
       " 'Germany',\n",
       " 'in',\n",
       " 'their',\n",
       " 'previous',\n",
       " 'friendly',\n",
       " 'England',\n",
       " 'failed',\n",
       " 'build',\n",
       " 'on',\n",
       " 'their',\n",
       " 'momentum',\n",
       " 'lost',\n",
       " '2',\n",
       " '1',\n",
       " 'to',\n",
       " 'Netherlands',\n",
       " 'Jamie',\n",
       " 'Vardy',\n",
       " 'man',\n",
       " 'of',\n",
       " 'match',\n",
       " 'scored',\n",
       " 'England',\n",
       " 'goal',\n",
       " 'with',\n",
       " 'slick',\n",
       " 'passing',\n",
       " 'move',\n",
       " 'that',\n",
       " 'led',\n",
       " 'to',\n",
       " 'cross',\n",
       " 'from',\n",
       " 'Kyle',\n",
       " 'Walker',\n",
       " 'England',\n",
       " 'defence',\n",
       " 'was',\n",
       " 'unable',\n",
       " 'protect',\n",
       " 'their',\n",
       " 'lead',\n",
       " 'Danny',\n",
       " 'Rose',\n",
       " 'was',\n",
       " 'punished',\n",
       " 'for',\n",
       " 'sloppy',\n",
       " 'pass',\n",
       " 'that',\n",
       " 'led',\n",
       " 'to',\n",
       " 'penalty',\n",
       " 'Vincent',\n",
       " 'Janssen',\n",
       " 'scored',\n",
       " 'winner',\n",
       " 'from',\n",
       " 'spot']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### clean_prompt\n",
    "### corrupted prompt \n",
    "\n",
    "# prompt_dict\n",
    "# summary_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc48781-2aa8-4581-bf9a-1955b843f564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (probe)",
   "language": "python",
   "name": "probe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
