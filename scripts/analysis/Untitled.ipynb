{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3fceb8-68e3-458b-91d8-cc3b18f5ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import uuid\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from scripts.utils import load_model\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54ae165-3d8a-4c87-937a-3421ce353403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c7deb5-38c7-4360-8d9d-620f88bbbfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8606ea346942688c9bcba2733227fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name = 'mistral7b'\n",
    "tokenizer, model = load_model(f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8b7901-f4c3-4b2f-b345-e1a1cc55630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def KL_divergence(P,Q):\n",
    "    # print(P * np.log(P / Q))\n",
    "    kl_values = P * np.log(P / Q)\n",
    "    kl_values = kl_values[np.isfinite(kl_values)]  # remove entries where p or q is 0\n",
    "    kl_div = np.sum(kl_values)\n",
    "    return kl_div\n",
    "    \n",
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return round(0.5 * (KL_divergence(_P, _M) + KL_divergence(_Q, _M)), 5)\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# p = [0.4, 0.3, 0.2, 0.1]\n",
    "# q = [0.2, 0.3, 0.4, 0.1]\n",
    "# jsd_value = JSD(p, q)\n",
    "# # jsd_value = jensen_shannon_divergence(p, q)\n",
    "# print(\"Jensen-Shannon Divergence:\", jsd_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a9991f-fcbd-4f74-aeb6-45add575d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_hstates_prediction(hstate, model):\n",
    "    logits = model.lm_head(hstate.to('cuda'))\n",
    "    probs = F.softmax(logits, dim=-1).cpu().detach()\n",
    "    predicted_tokens = []\n",
    "    for layer in probs:\n",
    "        predicted_tokens.append(torch.tensor([torch.argmax(layer).item()]))\n",
    "    assert(len(predicted_tokens) == probs.shape[0])\n",
    "    predicted_tokens = torch.stack(predicted_tokens, dim = 0)\n",
    "    return predicted_tokens, probs.cpu().detach().numpy()\n",
    "\n",
    "# P(O) across layers\n",
    "# P(M) across layers\n",
    "# Preicted token at each layer\n",
    "# JSD(V,M) for each layer\n",
    "# sim(H(l), H{l-1)) forr layers 2, 32\n",
    "# 0 - 32( 0 is embedding, 1 is layer 1, 32 is last layer))\n",
    "\n",
    "\n",
    "\n",
    "def make_layer_df(df_dict,\n",
    "                  layer_num,\n",
    "                  prob_dist,\n",
    "                  final_layer_prob,\n",
    "                  predicted_tokens,\n",
    "                 target_token):\n",
    "    \n",
    "    \n",
    "    jsd_final_layer = JSD(final_layer_prob, prob_dist)\n",
    "    \n",
    "    # print(layer_num, jsd_final_layer)\n",
    "    prob_dist = prob_dist.tolist()\n",
    "    \n",
    "    ### layer predicted token\n",
    "    pred_prob = max(prob_dist)\n",
    "    pred_token = predicted_tokens[layer_num].item()\n",
    "            \n",
    "    ### final generated token prob\n",
    "    target_token_prob = prob_dist[target_token]\n",
    "        \n",
    "    top3_predicted_probs = sorted(prob_dist, reverse = True)[:3]\n",
    "    top3_predicted_tokens = [prob_dist.index(each) for each in top3_predicted_probs]\n",
    "    # print(layer_num, pred_prob, pred_token, target_token, target_token_prob)\n",
    "    \n",
    "    jsd_key = f'jsd_layer{layer_num}'\n",
    "    df_dict[jsd_key] = [jsd_final_layer]\n",
    "\n",
    "    pred_prob_layer_key = f'pred_prob_layer{layer_num}'\n",
    "    df_dict[pred_prob_layer_key] = [pred_prob]\n",
    "    \n",
    "    pred_token_layer_key = f'pred_token_layer{layer_num}'\n",
    "    df_dict[pred_token_layer_key] = [pred_token]\n",
    "\n",
    "    target_prob_layer_key = f'target_prob_layer{layer_num}'\n",
    "    df_dict[target_prob_layer_key] = [target_token_prob]\n",
    "\n",
    "    top3_predicted_probs_key = f'top3_predicted_probs_layer{layer_num}'\n",
    "    df_dict[top3_predicted_probs_key] = [top3_predicted_probs]\n",
    "\n",
    "    top3_predicted_tokens_key = f'top3_predicted_tokens_layer{layer_num}'\n",
    "    df_dict[top3_predicted_tokens_key] = [top3_predicted_tokens]\n",
    "    return df_dict\n",
    "                \n",
    "def get_token_layer_info_dict(summ_token_hstates,\n",
    "                              target_token,\n",
    "                              factual_label,\n",
    "                              model):\n",
    "    \n",
    "    predicted_tokens, probs = get_hstates_prediction(summ_token_hstates, model)\n",
    "    \n",
    "    rand_token_id = uuid.uuid4()\n",
    "    df_dict = {\n",
    "            'target_token': [],\n",
    "            'label': []}\n",
    "    \n",
    "    df_dict['target_token'].append(f'{rand_token_id}_{target_token}')\n",
    "    \n",
    "    for layer_num in range(0, summ_token_hstates.shape[0]):\n",
    "        if layer_num > 0:\n",
    "            hidden_state_sim = cosine_similarity(summ_token_hstates[layer_num,:].unsqueeze(0), summ_token_hstates[layer_num- 1,:].unsqueeze(0))\n",
    "            hidden_state_sim = hidden_state_sim[0][0]\n",
    "            df_dict[f'prev_hidden_state_sim_layer{layer_num}'] = [hidden_state_sim]\n",
    "            \n",
    "    # print(summ_token_hstates.shape)\n",
    "    final_layer_prob = probs[-1]\n",
    "    # print(final_layer_prob.shape)\n",
    "    for layer_num in range(0, predicted_tokens.shape[0]):\n",
    "            prob_dist = probs[layer_num]\n",
    "            \n",
    "            \n",
    "            df_dict = make_layer_df(df_dict,\n",
    "                                    layer_num,\n",
    "                                    prob_dist,\n",
    "                                    final_layer_prob,\n",
    "                                    predicted_tokens,\n",
    "                                    target_token\n",
    "                                    )\n",
    "        \n",
    "    df_dict['label'].append(factual_label)\n",
    "    return pd.DataFrame(df_dict)\n",
    "    \n",
    "    \n",
    "def get_summary_layer_info(example, model):\n",
    "    # print(example)\n",
    "    source_len = example['source_len']\n",
    "    summary_len = example['summary_len']\n",
    "    hidden_states = example['hidden_states']\n",
    "    summary_tokens = example['all_tokens'][source_len: source_len + summary_len]\n",
    "    summary_token_labels = example['summary_token_labels']\n",
    "    if source_len.item() == 0:\n",
    "        summary_hidden_states = hidden_states\n",
    "    else:\n",
    "        summary_hidden_states = hidden_states[:, source_len - 1: (source_len + summary_len) - 1, :]\n",
    "    summary_hidden_states = summary_hidden_states.permute(1,0,2) ### we want to iterate of tokens not layers\n",
    "    df_list = []\n",
    "    \n",
    "    for idx, summ_token_hstates in enumerate(summary_hidden_states):\n",
    "        rand_token_id = uuid.uuid4()\n",
    "        target_token = summary_tokens[idx]\n",
    "        target_token_label = summary_token_labels[idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### hstate 0 is embedding \n",
    "        df_token_layer_info = get_token_layer_info_dict(summ_token_hstates, \n",
    "                                                        target_token = target_token,\n",
    "                                                        factual_label = target_token_label,\n",
    "                                                        model = model)\n",
    "        \n",
    "        df_list.append(df_token_layer_info)\n",
    "        \n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def make_prob_df(folder_path, model):\n",
    "    files = os.listdir(folder_path)\n",
    "    files = sorted(files)\n",
    "    dfs_data = []\n",
    "    all_docids = []\n",
    "    for file_name in tqdm(files):\n",
    "        docid = file_name.split('#')[-1].split('.pt')[0]\n",
    "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "            example = torch.load(os.path.join(folder_path, file_name))\n",
    "            # return example\n",
    "            df_example_dict = get_summary_layer_info(example, model)\n",
    "            all_docids += [docid] * len(df_example_dict)\n",
    "            dfs_data.append(df_example_dict)\n",
    "            # break\n",
    "    dfs_data = pd.concat(dfs_data)\n",
    "    dfs_data['docid'] = all_docids\n",
    "    return dfs_data\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e315a9-0f4b-4749-bc75-2276fd3a9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 44/62 [30:00<12:16, 40.91s/it]\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_data_document_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/llama7b/document_context')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[0;32m----> 3\u001b[0m df_data_document_context \u001b[38;5;241m=\u001b[39m \u001b[43mmake_prob_df\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/document_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# example.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# df_data_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/falcon7b/context_only')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 145\u001b[0m, in \u001b[0;36mmake_prob_df\u001b[0;34m(folder_path, model)\u001b[0m\n\u001b[1;32m    143\u001b[0m docid \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name)):\n\u001b[0;32m--> 145\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# return example\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     df_example_dict \u001b[38;5;241m=\u001b[39m get_summary_layer_info(example, model)\n",
      "File \u001b[0;32m~/.conda/envs/probe/lib/python3.8/site-packages/torch/serialization.py:1040\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/probe/lib/python3.8/site-packages/torch/serialization.py:1258\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1258\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# df_data_document_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/llama7b/document_context')\n",
    "print(model_name)\n",
    "df_data_document_context = make_prob_df(f'/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/{model_name}/document_context',\n",
    "                                       model)\n",
    "# example.\n",
    "# df_data_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/falcon7b/context_only')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac505faf-c79d-4e74-a975-9086892ce26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_document_context.to_csv(f'/scratch/ramprasad.sa/probing_summarization_factuality/metric_scores/layer_wise_uncertainty_{model_name}_xsum_document_context.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3351beb3-3a45-45b9-9510-809fc05211ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target_token</th>\n",
       "      <th>label</th>\n",
       "      <th>prev_hidden_state_sim_layer1</th>\n",
       "      <th>prev_hidden_state_sim_layer2</th>\n",
       "      <th>prev_hidden_state_sim_layer3</th>\n",
       "      <th>prev_hidden_state_sim_layer4</th>\n",
       "      <th>prev_hidden_state_sim_layer5</th>\n",
       "      <th>prev_hidden_state_sim_layer6</th>\n",
       "      <th>prev_hidden_state_sim_layer7</th>\n",
       "      <th>...</th>\n",
       "      <th>target_prob_layer31</th>\n",
       "      <th>top3_predicted_probs_layer31</th>\n",
       "      <th>top3_predicted_tokens_layer31</th>\n",
       "      <th>jsd_layer32</th>\n",
       "      <th>pred_prob_layer32</th>\n",
       "      <th>pred_token_layer32</th>\n",
       "      <th>target_prob_layer32</th>\n",
       "      <th>top3_predicted_probs_layer32</th>\n",
       "      <th>top3_predicted_tokens_layer32</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6c787a77-2b4d-4c51-9522-c81c33caa64b_10823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502231</td>\n",
       "      <td>0.697886</td>\n",
       "      <td>0.883980</td>\n",
       "      <td>0.879269</td>\n",
       "      <td>0.897342</td>\n",
       "      <td>0.843042</td>\n",
       "      <td>0.882769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>[0.00017794671293813735, 0.0001700913853710517...</td>\n",
       "      <td>[6735, 10823, 13]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>10823</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>[0.2968662679195404, 0.1760723739862442, 0.159...</td>\n",
       "      <td>[10823, 6735, 10598]</td>\n",
       "      <td>1701434231:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>e1a3216b-c2e9-494b-9aa6-b292fc58de32_346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640595</td>\n",
       "      <td>0.819120</td>\n",
       "      <td>0.855040</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.911790</td>\n",
       "      <td>0.923048</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>[0.00021923368331044912, 9.986708028009161e-05...</td>\n",
       "      <td>[346, 11394, 28724]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>346</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>[0.9999978542327881, 1.1988178130195593e-06, 4...</td>\n",
       "      <td>[346, 28724, 9880]</td>\n",
       "      <td>1701434231:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6ae7e2c0-5f81-48c8-9f85-5c208f6f27ea_4871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365209</td>\n",
       "      <td>0.634182</td>\n",
       "      <td>0.769403</td>\n",
       "      <td>0.839417</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.904766</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>[0.00045103655429556966, 0.0001499827631050720...</td>\n",
       "      <td>[4871, 4768, 8010]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>4871</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>[0.9999904632568359, 3.867198302032193e-06, 3....</td>\n",
       "      <td>[4871, 2, 809]</td>\n",
       "      <td>1701434231:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>73af10f7-ae43-4df8-9b4d-8acd80c25672_6859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737261</td>\n",
       "      <td>0.536919</td>\n",
       "      <td>0.812472</td>\n",
       "      <td>0.859449</td>\n",
       "      <td>0.917738</td>\n",
       "      <td>0.905706</td>\n",
       "      <td>0.902446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>[0.00036741080111823976, 0.0002478939713910222...</td>\n",
       "      <td>[6859, 9298, 2966]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957306</td>\n",
       "      <td>6859</td>\n",
       "      <td>0.957306</td>\n",
       "      <td>[0.9573062062263489, 0.025002170354127884, 0.0...</td>\n",
       "      <td>[6859, 2966, 9298]</td>\n",
       "      <td>1701434231:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3754be2e-c2cc-4bab-8783-a1a9a167d2da_3652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695037</td>\n",
       "      <td>0.832204</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>0.866248</td>\n",
       "      <td>0.895663</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.883450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>[0.0005028111627325416, 0.000221054840949364, ...</td>\n",
       "      <td>[3652, 8417, 17904]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993595</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.993595</td>\n",
       "      <td>[0.9935947060585022, 0.0046989042311906815, 0....</td>\n",
       "      <td>[3652, 28725, 2]</td>\n",
       "      <td>1701434231:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>0</td>\n",
       "      <td>2abebd58-40ec-45da-a163-26bcfadb6793_19046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.651269</td>\n",
       "      <td>0.891362</td>\n",
       "      <td>0.863759</td>\n",
       "      <td>0.917792</td>\n",
       "      <td>0.908955</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.881003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>[0.00038469236460514367, 0.0001789521920727566...</td>\n",
       "      <td>[19046, 481, 9044]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>19046</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>[0.9997829794883728, 8.023810369195417e-05, 4....</td>\n",
       "      <td>[19046, 481, 2]</td>\n",
       "      <td>1701478712:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>0</td>\n",
       "      <td>2239c2d1-c132-4b41-a39c-f3ea4e5c7b3d_297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.782844</td>\n",
       "      <td>0.846584</td>\n",
       "      <td>0.840643</td>\n",
       "      <td>0.906773</td>\n",
       "      <td>0.898784</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>[0.000254612386925146, 0.00014977669343352318,...</td>\n",
       "      <td>[297, 28725, 568]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945326</td>\n",
       "      <td>297</td>\n",
       "      <td>0.945326</td>\n",
       "      <td>[0.9453260898590088, 0.03830769285559654, 0.01...</td>\n",
       "      <td>[297, 28725, 28723]</td>\n",
       "      <td>1701478712:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>0</td>\n",
       "      <td>b29533f3-cd29-4070-ad4d-c5de9cd03a07_456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.628026</td>\n",
       "      <td>0.766359</td>\n",
       "      <td>0.788603</td>\n",
       "      <td>0.844659</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.875541</td>\n",
       "      <td>0.878498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>[0.0004337714344728738, 0.0002061405248241499,...</td>\n",
       "      <td>[456, 1178, 272]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975920</td>\n",
       "      <td>456</td>\n",
       "      <td>0.975920</td>\n",
       "      <td>[0.9759204387664795, 0.0224151611328125, 0.001...</td>\n",
       "      <td>[456, 1178, 272]</td>\n",
       "      <td>1701478712:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>0</td>\n",
       "      <td>8f124bc1-62c4-4ac6-81c6-4d05345795a2_2698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612289</td>\n",
       "      <td>0.820446</td>\n",
       "      <td>0.848606</td>\n",
       "      <td>0.908849</td>\n",
       "      <td>0.904515</td>\n",
       "      <td>0.899806</td>\n",
       "      <td>0.892966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>[0.0005920096882618964, 0.0002178939466830343,...</td>\n",
       "      <td>[2698, 5020, 1834]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>2698</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>[0.9992374181747437, 0.0004242497670929879, 7....</td>\n",
       "      <td>[2698, 1834, 4166]</td>\n",
       "      <td>1701478712:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>0</td>\n",
       "      <td>3fae0f7a-b8d2-45a1-9f11-1f1d7eadf747_28723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>0.776951</td>\n",
       "      <td>0.822176</td>\n",
       "      <td>0.893311</td>\n",
       "      <td>0.899137</td>\n",
       "      <td>0.913629</td>\n",
       "      <td>0.888935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>[0.00023149816843215376, 0.0001700091670500114...</td>\n",
       "      <td>[28725, 28723, 568]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747904</td>\n",
       "      <td>28725</td>\n",
       "      <td>0.205750</td>\n",
       "      <td>[0.7479038238525391, 0.20574986934661865, 0.02...</td>\n",
       "      <td>[28725, 28723, 568]</td>\n",
       "      <td>1701478712:mistral7b-ul2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8577 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                target_token  label  \\\n",
       "0              0  6c787a77-2b4d-4c51-9522-c81c33caa64b_10823      0   \n",
       "1              0    e1a3216b-c2e9-494b-9aa6-b292fc58de32_346      0   \n",
       "2              0   6ae7e2c0-5f81-48c8-9f85-5c208f6f27ea_4871      0   \n",
       "3              0   73af10f7-ae43-4df8-9b4d-8acd80c25672_6859      0   \n",
       "4              0   3754be2e-c2cc-4bab-8783-a1a9a167d2da_3652      0   \n",
       "...          ...                                         ...    ...   \n",
       "8572           0  2abebd58-40ec-45da-a163-26bcfadb6793_19046      0   \n",
       "8573           0    2239c2d1-c132-4b41-a39c-f3ea4e5c7b3d_297      0   \n",
       "8574           0    b29533f3-cd29-4070-ad4d-c5de9cd03a07_456      0   \n",
       "8575           0   8f124bc1-62c4-4ac6-81c6-4d05345795a2_2698      0   \n",
       "8576           0  3fae0f7a-b8d2-45a1-9f11-1f1d7eadf747_28723      0   \n",
       "\n",
       "      prev_hidden_state_sim_layer1  prev_hidden_state_sim_layer2  \\\n",
       "0                         0.502231                      0.697886   \n",
       "1                         0.640595                      0.819120   \n",
       "2                         0.365209                      0.634182   \n",
       "3                         0.737261                      0.536919   \n",
       "4                         0.695037                      0.832204   \n",
       "...                            ...                           ...   \n",
       "8572                      0.651269                      0.891362   \n",
       "8573                      0.673203                      0.782844   \n",
       "8574                      0.628026                      0.766359   \n",
       "8575                      0.612289                      0.820446   \n",
       "8576                      0.685451                      0.776951   \n",
       "\n",
       "      prev_hidden_state_sim_layer3  prev_hidden_state_sim_layer4  \\\n",
       "0                         0.883980                      0.879269   \n",
       "1                         0.855040                      0.901019   \n",
       "2                         0.769403                      0.839417   \n",
       "3                         0.812472                      0.859449   \n",
       "4                         0.810061                      0.866248   \n",
       "...                            ...                           ...   \n",
       "8572                      0.863759                      0.917792   \n",
       "8573                      0.846584                      0.840643   \n",
       "8574                      0.788603                      0.844659   \n",
       "8575                      0.848606                      0.908849   \n",
       "8576                      0.822176                      0.893311   \n",
       "\n",
       "      prev_hidden_state_sim_layer5  prev_hidden_state_sim_layer6  \\\n",
       "0                         0.897342                      0.843042   \n",
       "1                         0.911790                      0.923048   \n",
       "2                         0.898648                      0.904766   \n",
       "3                         0.917738                      0.905706   \n",
       "4                         0.895663                      0.868400   \n",
       "...                            ...                           ...   \n",
       "8572                      0.908955                      0.917567   \n",
       "8573                      0.906773                      0.898784   \n",
       "8574                      0.903000                      0.875541   \n",
       "8575                      0.904515                      0.899806   \n",
       "8576                      0.899137                      0.913629   \n",
       "\n",
       "      prev_hidden_state_sim_layer7  ...  target_prob_layer31  \\\n",
       "0                         0.882769  ...             0.000170   \n",
       "1                         0.887269  ...             0.000219   \n",
       "2                         0.915543  ...             0.000451   \n",
       "3                         0.902446  ...             0.000367   \n",
       "4                         0.883450  ...             0.000503   \n",
       "...                            ...  ...                  ...   \n",
       "8572                      0.881003  ...             0.000385   \n",
       "8573                      0.862941  ...             0.000255   \n",
       "8574                      0.878498  ...             0.000434   \n",
       "8575                      0.892966  ...             0.000592   \n",
       "8576                      0.888935  ...             0.000170   \n",
       "\n",
       "                           top3_predicted_probs_layer31  \\\n",
       "0     [0.00017794671293813735, 0.0001700913853710517...   \n",
       "1     [0.00021923368331044912, 9.986708028009161e-05...   \n",
       "2     [0.00045103655429556966, 0.0001499827631050720...   \n",
       "3     [0.00036741080111823976, 0.0002478939713910222...   \n",
       "4     [0.0005028111627325416, 0.000221054840949364, ...   \n",
       "...                                                 ...   \n",
       "8572  [0.00038469236460514367, 0.0001789521920727566...   \n",
       "8573  [0.000254612386925146, 0.00014977669343352318,...   \n",
       "8574  [0.0004337714344728738, 0.0002061405248241499,...   \n",
       "8575  [0.0005920096882618964, 0.0002178939466830343,...   \n",
       "8576  [0.00023149816843215376, 0.0001700091670500114...   \n",
       "\n",
       "      top3_predicted_tokens_layer31  jsd_layer32  pred_prob_layer32  \\\n",
       "0                 [6735, 10823, 13]          0.0           0.296866   \n",
       "1               [346, 11394, 28724]          0.0           0.999998   \n",
       "2                [4871, 4768, 8010]          0.0           0.999990   \n",
       "3                [6859, 9298, 2966]          0.0           0.957306   \n",
       "4               [3652, 8417, 17904]          0.0           0.993595   \n",
       "...                             ...          ...                ...   \n",
       "8572             [19046, 481, 9044]          0.0           0.999783   \n",
       "8573              [297, 28725, 568]          0.0           0.945326   \n",
       "8574               [456, 1178, 272]          0.0           0.975920   \n",
       "8575             [2698, 5020, 1834]          0.0           0.999237   \n",
       "8576            [28725, 28723, 568]          0.0           0.747904   \n",
       "\n",
       "      pred_token_layer32  target_prob_layer32  \\\n",
       "0                  10823             0.296866   \n",
       "1                    346             0.999998   \n",
       "2                   4871             0.999990   \n",
       "3                   6859             0.957306   \n",
       "4                   3652             0.993595   \n",
       "...                  ...                  ...   \n",
       "8572               19046             0.999783   \n",
       "8573                 297             0.945326   \n",
       "8574                 456             0.975920   \n",
       "8575                2698             0.999237   \n",
       "8576               28725             0.205750   \n",
       "\n",
       "                           top3_predicted_probs_layer32  \\\n",
       "0     [0.2968662679195404, 0.1760723739862442, 0.159...   \n",
       "1     [0.9999978542327881, 1.1988178130195593e-06, 4...   \n",
       "2     [0.9999904632568359, 3.867198302032193e-06, 3....   \n",
       "3     [0.9573062062263489, 0.025002170354127884, 0.0...   \n",
       "4     [0.9935947060585022, 0.0046989042311906815, 0....   \n",
       "...                                                 ...   \n",
       "8572  [0.9997829794883728, 8.023810369195417e-05, 4....   \n",
       "8573  [0.9453260898590088, 0.03830769285559654, 0.01...   \n",
       "8574  [0.9759204387664795, 0.0224151611328125, 0.001...   \n",
       "8575  [0.9992374181747437, 0.0004242497670929879, 7....   \n",
       "8576  [0.7479038238525391, 0.20574986934661865, 0.02...   \n",
       "\n",
       "      top3_predicted_tokens_layer32                     docid  \n",
       "0              [10823, 6735, 10598]  1701434231:mistral7b-ul2  \n",
       "1                [346, 28724, 9880]  1701434231:mistral7b-ul2  \n",
       "2                    [4871, 2, 809]  1701434231:mistral7b-ul2  \n",
       "3                [6859, 2966, 9298]  1701434231:mistral7b-ul2  \n",
       "4                  [3652, 28725, 2]  1701434231:mistral7b-ul2  \n",
       "...                             ...                       ...  \n",
       "8572                [19046, 481, 2]  1701478712:mistral7b-ul2  \n",
       "8573            [297, 28725, 28723]  1701478712:mistral7b-ul2  \n",
       "8574               [456, 1178, 272]  1701478712:mistral7b-ul2  \n",
       "8575             [2698, 1834, 4166]  1701478712:mistral7b-ul2  \n",
       "8576            [28725, 28723, 568]  1701478712:mistral7b-ul2  \n",
       "\n",
       "[8577 rows x 234 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646de48c-c503-4107-84b1-5bbcb86c1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tokens = list(df_data_document_context['layer_token32'].values)\n",
    "# for idx, tok in enumerate(all_tokens):\n",
    "#     print(tokenizer.decode(tok))\n",
    "def get_word_ids(df, \n",
    "                layer_name = 'layer_token32'):\n",
    "    all_tokens = list(df[layer_name].values)\n",
    "\n",
    "    words_idx = []\n",
    "    word_id = 0\n",
    "    for token_idx, token in enumerate(all_tokens):\n",
    "        if token_idx != 0:\n",
    "            prev_token = all_tokens[token_idx - 1]\n",
    "            word = tokenizer.decode([prev_token, token])\n",
    "            if len(word.split(' ')) > 1:\n",
    "                word_id += 1\n",
    "        words_idx.append(word_id)\n",
    "    return words_idx\n",
    "\n",
    "def make_word_boundaries(df):\n",
    "    df_wordidx = []\n",
    "    for unique_docid in list(set(df['docid'].values)):\n",
    "        df_docid = df[df['docid'] == unique_docid]\n",
    "        df_wordidx += get_word_ids(df_docid,\n",
    "                                layer_name = 'layer_token32')\n",
    "    assert(len(df_wordidx) == len(df))\n",
    "    df['word_id'] = df_wordidx\n",
    "    df['primary_key'] = [f\"{row['docid']}_{row['word_id']}\" for idx, row in df.iterrows()]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9332c8-cd3d-4284-bf36-b2df27c73d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30150/4294371539.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['word_id'] = df_wordidx\n",
      "/tmp/ipykernel_30150/4294371539.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['primary_key'] = [f\"{row['docid']}_{row['word_id']}\" for idx, row in df.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "df_data_document_context = make_word_boundaries(df_data_document_context)\n",
    "# df_data_context = make_word_boundaries(df_data_context)\n",
    "# df_data_context.head()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10be332-dd7c-4517-af6f-37e99e83c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual/Nonfactual split 6966 141\n"
     ]
    }
   ],
   "source": [
    "def get_sample(df):\n",
    "    df_sample_nonfactual = df[df['label'] == 1]\n",
    "    print('Factual/Nonfactual split', len(df[df['label'] == 0]), len(df_sample_nonfactual))\n",
    "    df_sample_factual = df[df['label'] == 0].sample(len(df_sample_nonfactual))\n",
    "    df_sample = pd.concat([df_sample_nonfactual, df_sample_factual\n",
    "                                           ])\n",
    "    return df_sample\n",
    "    \n",
    "df_sample_document_context = get_sample(df_data_document_context)\n",
    "# df_sample_context = get_sample(df_data_context)\n",
    "# df_sample_context = df_sample_context[df_sample_context['"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a7ddbf-1604-454c-9233-e7019ca56d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "sns.histplot(df_data_document_context[df_data_document_context['label'] == 0]['layer_prob32'],  \n",
    "             label='Factual Class',\n",
    "            ax = axes[0],\n",
    "            color='green')\n",
    "# sns.histplot(df_sample_document_context[df_sample_document_context['label'] == 1]['layer_prob32'],  \n",
    "#              label='Nonfactual Class',\n",
    "#             ax = axes[1],\n",
    "#             color='red')\n",
    "\n",
    "# sns.distplot(df_sample_document_context[df_sample_document_context['label'] == 1]['layer_prob32'], \n",
    "#              kde=True, \n",
    "#              label='Factual Class',\n",
    "#             ax = axes[1],\n",
    "#             kde_kws={'bw_method': 0.2, 'common_norm': True})\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(0, 1)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6c4d74-cbb6-4bcb-a559-5b7c3551810f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3033602285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    for unique_docid in\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for unique_docid in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89dda8b4-3dd2-4381-89e0-3a63ca70d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [    1, 26075,   264, 14060,   354,   272,  2296,  3248,   297,  6817,\\\n",
    "     28723,  1684,  6818,   272, 14060, 28725,   865,   938,  1871,   369,\n",
    "          349,  2169,   297,   272,  3248,  4192, 28738,  2431, 28747,  6735,\n",
    "        21351, 20067,  1342,   455,   392, 28725,  3890,   263, 16416,  5480,\n",
    "         9227, 28725,   659, 26097,   264,  2966,   369, 10823,   346,  4871,\n",
    "         6859,  3652, 28768,   339,  1337,  4403, 18811,   583,   583,   583,\n",
    "          583,   583,   583,   583,  1411,   568,   345,  3260,  2966,   622,\n",
    "         1316,  9850,   272, 10467,  1444,   905,   302,   272,  6735,  2191,\n",
    "         1207,   304,  1395,   477,   272,  6120, 28733, 28706, 10230,  4605,\n",
    "          862,  5480,  9227,  2240,   272, 16309,   568,   415,  3359, 28733,\n",
    "         1536,  1526, 12264,   349,   477,   272,  9308, 27737, 13784,  1665,\n",
    "          302,  2213,   508,   324,   568, 18811,   509,  4827, 28725,   693,\n",
    "          659,   750,  7394,   272,  2966,   354,   264,   879, 28725,  5397,\n",
    "          272,  3890,   263,   390,   396,   345,   583,   583,   583,   583,\n",
    "          583,   583, 14780,   568,   345, 28737,   837,  1215, 17434,   395,\n",
    "          272,  1069,  5480,  9227,   349,  5374,   559,  1411,   395,   579,\n",
    "         1188, 24594,   304, 15276, 28723,   816, 28742,   584,  1149,  2739,\n",
    "          356,   272,  2966,  1215,  3403, 28723,   315,  6253, 28742, 28707,\n",
    "         4496,   356,   693,   622,  1156,   559,  3905,   862, 18811,   509,\n",
    "         4827,  2240,   272, 16309,   568, 27186, 28725,  8577,   302,  6120,\n",
    "        28733, 28706, 10230,   905, 20841,   272,  6735,  9245,   302,   351,\n",
    "         2915,  1585, 28725, 13261,   282,   431,   304, 10540,   826, 20882,\n",
    "         4813,   288,   312,   783,   278,   282, 10813,   297,   272, 11088,\n",
    "          302, 18433,   533, 14650,  1444,   365, 11139, 26296,   304, 21731,\n",
    "          297,   272,  6120, 28733, 28706, 10230,  1665,   302,  3348,   314,\n",
    "          568,   415,  3890,   263,  2627,   630,   659,   750, 10728,   684,\n",
    "          559, 21668,   304,  3282,  3687,   297, 13261,   282,   431,   304,\n",
    "          345, 25327,   459,  9222,  4289,   438,  2125,   739,   456,   439,\n",
    "          350,   381,   403,  3344,  1633, 28739,   568,   415,  3057,   302,\n",
    "        21809,  8066,  8315,   369, 18811,   509,  4827, 28742, 28713,  2966,\n",
    "          356,   559,   622,  1316,  3081,   272,  2423,  1096,   345,   423,\n",
    "          905,   913,  1581,   562,   590,   460, 18161, 28723,   816,   506,\n",
    "          272,  1348,  1455,   594,   739,   272,  2939,   349,  5290, 28739,\n",
    "          568, 18811,   509,  4827, 28742, 28713, 13892, 17852,   969, 25694,\n",
    "          283, 28725,   693,   312,   331,   283,  1572,  5480,  9227, 28742,\n",
    "        28713,  1411,   304,  4677,   272,  6767, 28725,   622,  1863,   272,\n",
    "         2966,   568,  1092,   622,   583,   583,   583,   583,   583,   583,\n",
    "          583,   297,   272,  3890,   263, 28742, 28713,  1611,  1665,  2213,\n",
    "          508,   324, 28725,   970,  3939,   270,   392, 14547,  1190,   506,\n",
    "        24739,   264,  8743,   356, 10823,   346,  4871,  9922, 11030,   345,\n",
    "        28737,  3317,   583,   583,   583,   583,   583,   583,   583,   378,\n",
    "         1595,   411,   356,   586,  1411,  2838,   583,   583,   583,   583,\n",
    "          583,   583,   583,   263,   862,  5480,  9227,   773,   568,  5558,\n",
    "        28742, 28713,   306, 16982,  2966,  4779,   659, 13977,  7715,   356,\n",
    "        18978,   477,   272,  2939, 28742, 28713,  1043, 28733, 20603,  1061,\n",
    "         1006,  6120, 28733, 28706, 10230,  4605,   304,   272,  1664,  9922,\n",
    "          369,   506,   750,  1269,   506,  9045,   356,   272,  3939,   270,\n",
    "          392,  1488,  2821,  6094,   304,  5558, 28742, 28713,  5573, 28733,\n",
    "         1126,  2821,  2090,  8280,   297,   272,  4424, 28723,   318,  4171,\n",
    "        28755, 10713, 28747, 10823,   346,  4871,  6859,  3652, 28768,   339,\n",
    "         1337,  4403, 18811,   509,  4827,  6400,   298,  1038,   264,  2966,\n",
    "          356,  6735, 21351, 20067,  1342,   455,   392,  3890,   263, 16416,\n",
    "         5480,  9227, 28742, 28713,  1411, 28725,   395,  5480,  9227,  4746,\n",
    "        18063,   272,  2966,   390,   396, 16463,   298,  6735,  2525,   568,\n",
    "        18811,   509,  4827, 28725,   693,   659,   750,  7394,   272,  2966,\n",
    "          354,   264,   879, 28725,   349, 17434,   486,  5480,  9227, 28742,\n",
    "        28713,  9802,   304, 15276, 28725,   304,   659,   459,  2783,  4496,\n",
    "          356,   693,   622,  1156,   559,  3905,   568,   415,  2966,   349,\n",
    "         3349,   298,  9850,   272, 10467,  1444,   905,   477,   272,  6735,\n",
    "         2191,  1207,   304,  1395,   477,   272,  6120, 28733, 28706, 10230,\n",
    "         4605, 28723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3544822-5acc-4f74-8237-a271806b7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramprasad.sa/.conda/envs/probe/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.1',\n",
    "                                         cache_dir = '/scratch/ramprasad.sa/huggingface_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b879ef55-93a8-4e60-bda1-7a077b9ff50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = tokenizer.decode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec2c7be8-9c84-4d49-ae42-77a75bc7055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1, 26075, 264, 14060, 354, 272, 2296, 3248, 297, 6817, 28723, 1684, 6818, 272, 14060, 28725, 865, 938, 1871, 369, 349, 2169, 297, 272, 3248, 4192, 28738, 2431, 28747, 6735, 21351, 20067, 1342, 455, 392, 28725, 3890, 263, 16416, 5480, 9227, 28725, 659, 26097, 264, 2966, 369, 10823, 346, 4871, 6859, 3652, 28768, 339, 1337, 4403, 18811, \\\n",
    "     583, 583, 583, 583, 583, 583, 583, 1411, 568, 345, 3260, 2966, 622, 1316, 9850, 272, 10467, 1444, 905, 302, 272, 6735, 2191,\\\n",
    "     1207, 304, 1395, 477, 272, 6120, 28733, 28706, 10230, 4605, 862, 5480, 9227, 2240, 272, 16309, 568, 415, 3359, 28733, 1536, 1526, 12264, 349, 477, 272, 9308, 27737, 13784, 1665, 302, 2213, 508, 324, 568, 18811, 509, 4827, 28725, 693, 659, \\\n",
    "     750, 7394, 272, 2966, 354, 264, 879, 28725, 5397, 272, 3890, 263, 390, 396, 345, 583, 583, 583, 583, 583, 583, 583, 28739, 568, 345, 28737, 837, 1215, 17434, 395, 272, 1069, 5480, 9227, 349, 5374, 559, 1411, 395, 579, 1188, 24594, 304, \\\n",
    "     15276, 28723, 816, 28742, 584, 1149, 2739, 356, 272, 2966, 1215, 3403, 28723, 315, 6253, 28742, 28707, 4496, 356, 693, 622, 1156, 559, 3905, 862, 18811, 509, 4827, 2240, 272, 16309, 568, 27186, 28725, 8577, 302, 6120, 28733, 28706, 10230, 905, \\\n",
    "     20841, 272, 6735, 9245, 302, 351, 2915, 1585, 28725, 13261, 282, 431, 304, 10540, 826, 20882, 4813, 288, 312, 783, 278, 282, 10813, 297, 272, 11088, 302, 18433, 533, 14650, 1444, 365, 11139, 26296, 304, 21731, 297, 272, 6120, 28733, 28706, \\\n",
    "     10230, 1665, 302, 3348, 314, 568, 415, 3890, 263, 2627, 630, 659, 750, 10728, 684, 559, 21668, 304, 3282, 3687, 297, 13261, 282, 431, 304, 345, 25327, 459, 9222, 4289, 438, 2125, 739, 456, 439, 350, 381, 403, 3344, 1633, 28739, 568, 415, \\\n",
    "     3057, 302, 21809, 8066, 8315, 369, 18811, 509, 4827, 28742, 28713, 2966, 356, 559, 622, 1316, 3081, 272, 2423, 1096, 345, 423, 905, 913, 1581, 562, 590, 460, 18161, 28723, 816, 506, 272, 1348, 1455, 594, 739, 272, 2939, 349, 5290, 28739, \\\n",
    "     568, 18811, 509, 4827, 28742, 28713, 13892, 17852, 969, 25694, 283, 28725, 693, 312, 331, 283, 1572, 5480, 9227, 28742, 28713, 1411, 304, 4677, 272, 6767, 28725, 622, 1863, 272, 2966, 568, 1092, 622, 583, 583, 583, 583, 583, 583, 583, 297, \\\n",
    "     272, 3890, 263, 28742, 28713, 1611, 1665, 2213, 508, 324, 28725, 970, 3939, 270, 392, 14547, 1190, 506, 24739, 264, 8743, 356, 10823, 346, 4871, 9922, 11030, 345, 28737, 3317, 583, 583, 583, 583, 583, 583, 583, 378, 1595, 411, 356,\n",
    "     586, 1411, 2838, 583, 583, 583, 583, 583, 583, 583, 263, 862, 5480, 9227, 773, 568, 5558, 28742, 28713, 306, 16982, 2966, 4779, 659, 13977, 7715, 356, 18978, 477, 272, 2939, 28742, 28713, 1043, 28733, 20603, 1061, 1006, 6120, 28733, 28706, \\\n",
    "     10230, 4605, 304, 272, 1664, 9922, 369, 506, 750, 1269, 506, 9045, 356, 272, 3939, 270, 392, 1488, 2821, 6094, 304, 5558, 28742, 28713, 5573, 28733, 1126, 2821, 2090, 8280, 297, 272, 4424, 28723, 318, 4171, 28755, 10713, 28747, 10823, 346, \\\n",
    "     4871, 6859, 3652, 28768, 339, 1337, 4403, 18811, 509, 4827, 6400, 298, 1038, 264, 2966, 356, 6735, 21351, 20067, 1342, 455, 392, 3890, 263, 16416, 5480, 9227, 28742, 28713, 1411, 28725, 395, 5480, 9227, 4746, 18063, 272, 2966, 390, 396, \\\n",
    "     16463, 298, 6735, 2525, 568, 18811, 509, 4827, 28725, 693, 659, 750, 7394, 272, 2966, 354, 264, 879, 28725, 349, 17434, 486, 5480, 9227, 28742, 28713, 9802, 304, 15276, 28725, 304, 659, 459, 2783, 4496, 356, 693, 622, 1156, 559, 3905,568, \\\n",
    "     415, 2966, 349, 3349, 298, 9850, 272, 10467, 1444, 905, 477, 272, 6735, 2191, 1207, 304, 1395, 477, 272, 6120, 28733, 28706, 10230, 4605, 28723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89361fd7-bcac-453b-85d1-efb3c6722c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2 = tokenizer.decode(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae37fc4-c23b-495e-88fc-fe45c6a8b867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 == str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b009854-cb56-48ac-bf11-5f3174204763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce7af507-f4f0-4d3c-8ecd-03f62cd52059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Generate a summary for the following document in brief. When creating the summary, only use information that is present in the document CONTENT: Indian Olympics bronze medallist, boxer MC Mary Kom, has welcomed a film that Bollywood director Sanjay Leela Bh _ _ _ _ _ _ _ life.. \"This film will help bridge the gap between people of the Indian mainland and those from the north-eastern states,\" Mary Kom told the BBC.. The five-time world champion is from the remote northeast state of Manipur.. Bhansali, who has been planning the film for a year, described the boxer as an \" _ _ _ _ _ _ _\".. \"I am very impressed with the way Mary Kom is leading her life with so much conviction and courage. We\\'ll start working on the film very soon. I haven\\'t decided on who will play her role,\" Bhansali told the BBC.. Recently, thousands of north-eastern people fled the Indian cities of Mumbai, Bangalore and Hyderabad fearing reprisal attacks in the wake of ethnic clashes between Bodo tribes and Muslims in the north-eastern state of Assam.. The boxer says she has been worried about her relatives and friends living in Bangalore and \"could not properly sleep at night when this exodus was taking place\".. The mother of twin boys feels that Bhansali\\'s film on her will help clear the air because \"our people look different but they are Indians. We have the same passions when the country is involved\".. Bhansali\\'s assistant Omung Kumar, who researched Mary Kom\\'s life and wrote the script, will direct the film.. But will _ _ _ _ _ _ _ in the boxer\\'s home state Manipur, where separatist rebels have imposed a ban on Bollywood films?. \"I hope _ _ _ _ _ _ _ it centres on my life story _ _ _ _ _ _ _er,\" Mary Kom said.. India\\'s thriving film industry has rarely picked on themes from the country\\'s long-embattled north-eastern states and the few films that have been made have focused on the separatist insurgencies and India\\'s counter-insurgency efforts in the region. SUMMARY: Bollywood director Sanjay Leela Bhansali plans to make a film on Indian Olympics bronze medallist boxer MC Mary Kom\\'s life, with Mary Kom herself describing the film as an inspiration to Indian women.. Bhansali, who has been planning the film for a year, is impressed by Mary Kom\\'s leadership and courage, and has not yet decided on who will play her role.. The film is expected to bridge the gap between people from the Indian mainland and those from the north-eastern states.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e600efcb-890b-4d85-912c-23b801a17d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23128/3615579252.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = torch.tensor(a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([602])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "856222d4-8e73-4c07-a671-ea8349ca7a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23128/3593657194.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([603])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3c6c40-3682-4f0c-939f-6a764e147792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  583, 14780,   568,   345, 28737,   837,  1215, 17434,   395,   272,\n",
       "         1069,  5480,  9227,   349,  5374,   559,  1411,   395,   579,  1188,\n",
       "        24594,   304, 15276, 28723,   816, 28742,   584,  1149,  2739,   356,\n",
       "          272,  2966,  1215,  3403, 28723,   315,  6253, 28742, 28707,  4496,\n",
       "          356,   693,   622,  1156,   559,  3905,   862, 18811,   509,  4827,\n",
       "         2240,   272, 16309,   568, 27186, 28725,  8577,   302,  6120, 28733,\n",
       "        28706, 10230,   905, 20841,   272,  6735,  9245,   302,   351,  2915,\n",
       "         1585, 28725, 13261,   282,   431,   304, 10540,   826, 20882,  4813,\n",
       "          288,   312,   783,   278,   282, 10813,   297,   272, 11088,   302,\n",
       "        18433,   533, 14650,  1444,   365, 11139, 26296,   304, 21731,   297,\n",
       "          272,  6120, 28733, 28706, 10230,  1665,   302,  3348,   314,   568,\n",
       "          415,  3890,   263,  2627,   630,   659,   750, 10728,   684,   559,\n",
       "        21668,   304,  3282,  3687,   297, 13261,   282,   431,   304,   345,\n",
       "        25327,   459,  9222,  4289,   438,  2125,   739,   456,   439,   350,\n",
       "          381,   403,  3344,  1633, 28739,   568,   415,  3057,   302, 21809,\n",
       "         8066,  8315,   369, 18811,   509,  4827, 28742, 28713,  2966,   356,\n",
       "          559,   622,  1316,  3081,   272,  2423,  1096,   345,   423,   905,\n",
       "          913,  1581,   562,   590,   460, 18161, 28723,   816,   506,   272,\n",
       "         1348,  1455,   594,   739,   272,  2939,   349,  5290, 28739,   568,\n",
       "        18811,   509,  4827, 28742, 28713, 13892, 17852,   969, 25694,   283,\n",
       "        28725,   693,   312,   331,   283,  1572,  5480,  9227, 28742, 28713,\n",
       "         1411,   304,  4677,   272,  6767, 28725,   622,  1863,   272,  2966,\n",
       "          568,  1092,   622,   583,   583,   583,   583,   583,   583,   583,\n",
       "          297,   272,  3890,   263, 28742, 28713,  1611,  1665,  2213,   508,\n",
       "          324, 28725,   970,  3939,   270,   392, 14547,  1190,   506, 24739,\n",
       "          264,  8743,   356, 10823,   346,  4871,  9922, 11030,   345, 28737,\n",
       "         3317,   583,   583,   583,   583,   583,   583,   583,   378,  1595,\n",
       "          411,   356,   586,  1411,  2838,   583,   583,   583,   583,   583,\n",
       "          583,   583,   263,   862,  5480,  9227,   773,   568,  5558, 28742,\n",
       "        28713,   306, 16982,  2966,  4779,   659, 13977,  7715,   356, 18978,\n",
       "          477,   272,  2939, 28742, 28713,  1043, 28733, 20603,  1061,  1006,\n",
       "         6120, 28733, 28706, 10230,  4605,   304,   272,  1664,  9922,   369,\n",
       "          506,   750,  1269,   506,  9045,   356,   272,  3939,   270,   392,\n",
       "         1488,  2821,  6094,   304,  5558, 28742, 28713,  5573, 28733,  1126,\n",
       "         2821,  2090,  8280,   297,   272,  4424, 28723,   318,  4171, 28755,\n",
       "        10713, 28747, 10823,   346,  4871,  6859,  3652, 28768,   339,  1337,\n",
       "         4403, 18811,   509,  4827,  6400,   298,  1038,   264,  2966,   356,\n",
       "         6735, 21351, 20067,  1342,   455,   392,  3890,   263, 16416,  5480,\n",
       "         9227, 28742, 28713,  1411, 28725,   395,  5480,  9227,  4746, 18063,\n",
       "          272,  2966,   390,   396, 16463,   298,  6735,  2525,   568, 18811,\n",
       "          509,  4827, 28725,   693,   659,   750,  7394,   272,  2966,   354,\n",
       "          264,   879, 28725,   349, 17434,   486,  5480,  9227, 28742, 28713,\n",
       "         9802,   304, 15276, 28725,   304,   659,   459,  2783,  4496,   356,\n",
       "          693,   622,  1156,   559,  3905,   568,   415,  2966,   349,  3349,\n",
       "          298,  9850,   272, 10467,  1444,   905,   477,   272,  6735,  2191,\n",
       "         1207,   304,  1395,   477,   272,  6120, 28733, 28706, 10230,  4605,\n",
       "        28723])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for idx in range(0, 601):\n",
    "#     if a[idx] != b[idx]:\n",
    "#         print(idx)\n",
    "\n",
    "a[141:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "116311c7-cdd1-4a12-b38a-d8414a9ac5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  583,   583, 28739,   568,   345, 28737,   837,  1215, 17434,   395,\n",
       "          272,  1069,  5480,  9227,   349,  5374,   559,  1411,   395,   579,\n",
       "         1188, 24594,   304, 15276, 28723,   816, 28742,   584,  1149,  2739,\n",
       "          356,   272,  2966,  1215,  3403, 28723,   315,  6253, 28742, 28707,\n",
       "         4496,   356,   693,   622,  1156,   559,  3905,   862, 18811,   509,\n",
       "         4827,  2240,   272, 16309,   568, 27186, 28725,  8577,   302,  6120,\n",
       "        28733, 28706, 10230,   905, 20841,   272,  6735,  9245,   302,   351,\n",
       "         2915,  1585, 28725, 13261,   282,   431,   304, 10540,   826, 20882,\n",
       "         4813,   288,   312,   783,   278,   282, 10813,   297,   272, 11088,\n",
       "          302, 18433,   533, 14650,  1444,   365, 11139, 26296,   304, 21731,\n",
       "          297,   272,  6120, 28733, 28706, 10230,  1665,   302,  3348,   314,\n",
       "          568,   415,  3890,   263,  2627,   630,   659,   750, 10728,   684,\n",
       "          559, 21668,   304,  3282,  3687,   297, 13261,   282,   431,   304,\n",
       "          345, 25327,   459,  9222,  4289,   438,  2125,   739,   456,   439,\n",
       "          350,   381,   403,  3344,  1633, 28739,   568,   415,  3057,   302,\n",
       "        21809,  8066,  8315,   369, 18811,   509,  4827, 28742, 28713,  2966,\n",
       "          356,   559,   622,  1316,  3081,   272,  2423,  1096,   345,   423,\n",
       "          905,   913,  1581,   562,   590,   460, 18161, 28723,   816,   506,\n",
       "          272,  1348,  1455,   594,   739,   272,  2939,   349,  5290, 28739,\n",
       "          568, 18811,   509,  4827, 28742, 28713, 13892, 17852,   969, 25694,\n",
       "          283, 28725,   693,   312,   331,   283,  1572,  5480,  9227, 28742,\n",
       "        28713,  1411,   304,  4677,   272,  6767, 28725,   622,  1863,   272,\n",
       "         2966,   568,  1092,   622,   583,   583,   583,   583,   583,   583,\n",
       "          583,   297,   272,  3890,   263, 28742, 28713,  1611,  1665,  2213,\n",
       "          508,   324, 28725,   970,  3939,   270,   392, 14547,  1190,   506,\n",
       "        24739,   264,  8743,   356, 10823,   346,  4871,  9922, 11030,   345,\n",
       "        28737,  3317,   583,   583,   583,   583,   583,   583,   583,   378,\n",
       "         1595,   411,   356,   586,  1411,  2838,   583,   583,   583,   583,\n",
       "          583,   583,   583,   263,   862,  5480,  9227,   773,   568,  5558,\n",
       "        28742, 28713,   306, 16982,  2966,  4779,   659, 13977,  7715,   356,\n",
       "        18978,   477,   272,  2939, 28742, 28713,  1043, 28733, 20603,  1061,\n",
       "         1006,  6120, 28733, 28706, 10230,  4605,   304,   272,  1664,  9922,\n",
       "          369,   506,   750,  1269,   506,  9045,   356,   272,  3939,   270,\n",
       "          392,  1488,  2821,  6094,   304,  5558, 28742, 28713,  5573, 28733,\n",
       "         1126,  2821,  2090,  8280,   297,   272,  4424, 28723,   318,  4171,\n",
       "        28755, 10713, 28747, 10823,   346,  4871,  6859,  3652, 28768,   339,\n",
       "         1337,  4403, 18811,   509,  4827,  6400,   298,  1038,   264,  2966,\n",
       "          356,  6735, 21351, 20067,  1342,   455,   392,  3890,   263, 16416,\n",
       "         5480,  9227, 28742, 28713,  1411, 28725,   395,  5480,  9227,  4746,\n",
       "        18063,   272,  2966,   390,   396, 16463,   298,  6735,  2525,   568,\n",
       "        18811,   509,  4827, 28725,   693,   659,   750,  7394,   272,  2966,\n",
       "          354,   264,   879, 28725,   349, 17434,   486,  5480,  9227, 28742,\n",
       "        28713,  9802,   304, 15276, 28725,   304,   659,   459,  2783,  4496,\n",
       "          356,   693,   622,  1156,   559,  3905,   568,   415,  2966,   349,\n",
       "         3349,   298,  9850,   272, 10467,  1444,   905,   477,   272,  6735,\n",
       "         2191,  1207,   304,  1395,   477,   272,  6120, 28733, 28706, 10230,\n",
       "         4605, 28723])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[141:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2a5aebf-24dc-45c5-8dae-56ece2f57468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk><unk>\".. \"I am very impressed with the way Mary'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,   0, 28739,   568,   345, 28737,   837,  1215, 17434,   395,\n",
    "          272,  1069,  5480,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e382207-b456-44bb-857d-b92cdb49991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk><unk>\".. \"I am very impressed with the way Mary'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tokenizer.decode([1, 0,   0, 28739,   568,   345, 28737,   837,  1215, 17434,   395,\n",
    "          272,  1069,  5480])\n",
    "temp.split('<s>')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "800fcadf-1a8f-42ce-ae9e-eeae2057a0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Generate a summary for the following'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1,26075,   264, 14060,   354,   272,  2296])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd88f135-88c3-4c8d-8e51-516323dcb191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_ _\".. \"I am very impressed with the way Mary'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32eeffbc-e91a-4b60-847f-3236d2102589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>\"'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0, 28739])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1c37842-1247-4a95-b3e8-af8d72751801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 345], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b4c7aca-1b1a-48f3-a18d-c207c9c1a3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tokenizer.unk_token).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52d37b64-10bc-483e-bbdc-6610c91601b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 583, 28705], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('_ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf06f994-8943-46c4-95b1-4efc03372930",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[MASK]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/probe/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:935\u001b[0m, in \u001b[0;36mSpecialTokensMixin.add_special_tokens\u001b[0;34m(self, special_tokens_dict, replace_additional_special_tokens)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    934\u001b[0m added_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mspecial_tokens_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSPECIAL_TOKENS_ATTRIBUTES, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a special token\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(\"[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e02c139-c48c-4e73-a455-c1e94ed6a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(['[MASK]'], special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71f63205-9574-4458-a585-784a73426d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 32000], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04830c64-2309-46d7-ba55-b1fe530569b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (probe)",
   "language": "python",
   "name": "probe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
