{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3fceb8-68e3-458b-91d8-cc3b18f5ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import uuid\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from scripts.utils import load_model\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54ae165-3d8a-4c87-937a-3421ce353403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c7deb5-38c7-4360-8d9d-620f88bbbfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd291b087a224f009c37072977194399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name = 'mistral7b'\n",
    "tokenizer, model = load_model(f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c8b7901-f4c3-4b2f-b345-e1a1cc55630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def KL_divergence(P,Q):\n",
    "    # print(P * np.log(P / Q))\n",
    "    kl_values = P * np.log(P / Q)\n",
    "    kl_values = kl_values[np.isfinite(kl_values)]  # remove entries where p or q is 0\n",
    "    kl_div = np.sum(kl_values)\n",
    "    return kl_div\n",
    "    \n",
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return round(0.5 * (KL_divergence(_P, _M) + KL_divergence(_Q, _M)), 5)\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# p = [0.4, 0.3, 0.2, 0.1]\n",
    "# q = [0.2, 0.3, 0.4, 0.1]\n",
    "# jsd_value = JSD(p, q)\n",
    "# # jsd_value = jensen_shannon_divergence(p, q)\n",
    "# print(\"Jensen-Shannon Divergence:\", jsd_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a9991f-fcbd-4f74-aeb6-45add575d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_hstates_prediction(hstate, model):\n",
    "    logits = model.lm_head(hstate.to('cuda'))\n",
    "    probs = F.softmax(logits, dim=-1).cpu().detach()\n",
    "    predicted_tokens = []\n",
    "    for layer in probs:\n",
    "        predicted_tokens.append(torch.tensor([torch.argmax(layer).item()]))\n",
    "    assert(len(predicted_tokens) == probs.shape[0])\n",
    "    predicted_tokens = torch.stack(predicted_tokens, dim = 0)\n",
    "    return predicted_tokens, probs.cpu().detach().numpy()\n",
    "\n",
    "# P(O) across layers\n",
    "# P(M) across layers\n",
    "# Preicted token at each layer\n",
    "# JSD(V,M) for each layer\n",
    "# sim(H(l), H{l-1)) forr layers 2, 32\n",
    "# 0 - 32( 0 is embedding, 1 is layer 1, 32 is last layer))\n",
    "\n",
    "\n",
    "\n",
    "def make_layer_df(df_dict,\n",
    "                  layer_num,\n",
    "                  prob_dist,\n",
    "                  final_layer_prob,\n",
    "                  predicted_tokens,\n",
    "                 target_token):\n",
    "    \n",
    "    \n",
    "    jsd_final_layer = JSD(final_layer_prob, prob_dist)\n",
    "    \n",
    "    # print(layer_num, jsd_final_layer)\n",
    "    prob_dist = prob_dist.tolist()\n",
    "    \n",
    "    ### layer predicted token\n",
    "    pred_prob = max(prob_dist)\n",
    "    pred_token = predicted_tokens[layer_num].item()\n",
    "            \n",
    "    ### final generated token prob\n",
    "    target_token_prob = prob_dist[target_token]\n",
    "        \n",
    "    top3_predicted_probs = sorted(prob_dist, reverse = True)[:3]\n",
    "    top3_predicted_tokens = [prob_dist.index(each) for each in top3_predicted_probs]\n",
    "    # print(layer_num, pred_prob, pred_token, target_token, target_token_prob)\n",
    "    \n",
    "    jsd_key = f'jsd_layer{layer_num}'\n",
    "    df_dict[jsd_key] = [jsd_final_layer]\n",
    "\n",
    "    pred_prob_layer_key = f'pred_prob_layer{layer_num}'\n",
    "    df_dict[pred_prob_layer_key] = [pred_prob]\n",
    "    \n",
    "    pred_token_layer_key = f'pred_token_layer{layer_num}'\n",
    "    df_dict[pred_token_layer_key] = [pred_token]\n",
    "\n",
    "    target_prob_layer_key = f'target_prob_layer{layer_num}'\n",
    "    df_dict[target_prob_layer_key] = [target_token_prob]\n",
    "\n",
    "    top3_predicted_probs_key = f'top3_predicted_probs_layer{layer_num}'\n",
    "    df_dict[top3_predicted_probs_key] = [top3_predicted_probs]\n",
    "\n",
    "    top3_predicted_tokens_key = f'top3_predicted_tokens_layer{layer_num}'\n",
    "    df_dict[top3_predicted_tokens_key] = [top3_predicted_tokens]\n",
    "    return df_dict\n",
    "                \n",
    "def get_token_layer_info_dict(summ_token_hstates,\n",
    "                              target_token,\n",
    "                              factual_label,\n",
    "                              model):\n",
    "    \n",
    "    predicted_tokens, probs = get_hstates_prediction(summ_token_hstates, model)\n",
    "    \n",
    "    rand_token_id = uuid.uuid4()\n",
    "    df_dict = {\n",
    "            'target_token': [],\n",
    "            'label': []}\n",
    "    \n",
    "    df_dict['target_token'].append(f'{rand_token_id}_{target_token}')\n",
    "    \n",
    "    for layer_num in range(0, summ_token_hstates.shape[0]):\n",
    "        if layer_num > 0:\n",
    "            hidden_state_sim = cosine_similarity(summ_token_hstates[layer_num,:].unsqueeze(0), summ_token_hstates[layer_num- 1,:].unsqueeze(0))\n",
    "            hidden_state_sim = hidden_state_sim[0][0]\n",
    "            df_dict[f'prev_hidden_state_sim_layer{layer_num}'] = [hidden_state_sim]\n",
    "            \n",
    "    # print(summ_token_hstates.shape)\n",
    "    final_layer_prob = probs[-1]\n",
    "    # print(final_layer_prob.shape)\n",
    "    for layer_num in range(0, predicted_tokens.shape[0]):\n",
    "            prob_dist = probs[layer_num]\n",
    "            \n",
    "            \n",
    "            df_dict = make_layer_df(df_dict,\n",
    "                                    layer_num,\n",
    "                                    prob_dist,\n",
    "                                    final_layer_prob,\n",
    "                                    predicted_tokens,\n",
    "                                    target_token\n",
    "                                    )\n",
    "        \n",
    "    df_dict['label'].append(factual_label)\n",
    "    return pd.DataFrame(df_dict)\n",
    "    \n",
    "    \n",
    "def get_summary_layer_info(example, model):\n",
    "    # print(example)\n",
    "    source_len = example['source_len']\n",
    "    summary_len = example['summary_len']\n",
    "    hidden_states = example['hidden_states']\n",
    "    summary_tokens = example['all_tokens'][source_len: source_len + summary_len]\n",
    "    summary_token_labels = example['summary_token_labels']\n",
    "    if source_len.item() == 0:\n",
    "        summary_hidden_states = hidden_states\n",
    "    else:\n",
    "        summary_hidden_states = hidden_states[:, source_len - 1: (source_len + summary_len) - 1, :]\n",
    "    summary_hidden_states = summary_hidden_states.permute(1,0,2) ### we want to iterate of tokens not layers\n",
    "    df_list = []\n",
    "    \n",
    "    for idx, summ_token_hstates in enumerate(summary_hidden_states):\n",
    "        rand_token_id = uuid.uuid4()\n",
    "        target_token = summary_tokens[idx]\n",
    "        target_token_label = summary_token_labels[idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### hstate 0 is embedding \n",
    "        df_token_layer_info = get_token_layer_info_dict(summ_token_hstates, \n",
    "                                                        target_token = target_token,\n",
    "                                                        factual_label = target_token_label,\n",
    "                                                        model = model)\n",
    "        \n",
    "        df_list.append(df_token_layer_info)\n",
    "        \n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def make_prob_df(folder_path, model):\n",
    "    files = os.listdir(folder_path)\n",
    "    files = sorted(files)\n",
    "    dfs_data = []\n",
    "    all_docids = []\n",
    "    for file_name in tqdm(files):\n",
    "        docid = file_name.split('#')[-1].split('.pt')[0]\n",
    "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "            example = torch.load(os.path.join(folder_path, file_name))\n",
    "            # return example\n",
    "            df_example_dict = get_summary_layer_info(example, model)\n",
    "            all_docids += [docid] * len(df_example_dict)\n",
    "            dfs_data.append(df_example_dict)\n",
    "            # break\n",
    "    dfs_data = pd.concat(dfs_data)\n",
    "    dfs_data['docid'] = all_docids\n",
    "    return dfs_data\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e315a9-0f4b-4749-bc75-2276fd3a9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [40:17<00:00, 39.00s/it]\n",
      "/tmp/ipykernel_17707/1801410697.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs_data['docid'] = all_docids\n"
     ]
    }
   ],
   "source": [
    "# df_data_document_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/llama7b/document_context')\n",
    "print(model_name)\n",
    "df_data_document_context = make_prob_df(f'/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/{model_name}/document_context')\n",
    "# example.\n",
    "# df_data_context= make_prob_df('/scratch/ramprasad.sa/probing_summarization_factuality/internal_states/USB/XSUM/falcon7b/context_only')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac505faf-c79d-4e74-a975-9086892ce26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_document_context.to_csv(f'/scratch/ramprasad.sa/probing_summarization_factuality/metric_scores/layer_wise_uncertainty_{model_name}_xsum_document_context.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3351beb3-3a45-45b9-9510-809fc05211ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006782390992157161"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_data_document_context['target_prob_layer29'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646de48c-c503-4107-84b1-5bbcb86c1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tokens = list(df_data_document_context['layer_token32'].values)\n",
    "# for idx, tok in enumerate(all_tokens):\n",
    "#     print(tokenizer.decode(tok))\n",
    "def get_word_ids(df, \n",
    "                layer_name = 'layer_token32'):\n",
    "    all_tokens = list(df[layer_name].values)\n",
    "\n",
    "    words_idx = []\n",
    "    word_id = 0\n",
    "    for token_idx, token in enumerate(all_tokens):\n",
    "        if token_idx != 0:\n",
    "            prev_token = all_tokens[token_idx - 1]\n",
    "            word = tokenizer.decode([prev_token, token])\n",
    "            if len(word.split(' ')) > 1:\n",
    "                word_id += 1\n",
    "        words_idx.append(word_id)\n",
    "    return words_idx\n",
    "\n",
    "def make_word_boundaries(df):\n",
    "    df_wordidx = []\n",
    "    for unique_docid in list(set(df['docid'].values)):\n",
    "        df_docid = df[df['docid'] == unique_docid]\n",
    "        df_wordidx += get_word_ids(df_docid,\n",
    "                                layer_name = 'layer_token32')\n",
    "    assert(len(df_wordidx) == len(df))\n",
    "    df['word_id'] = df_wordidx\n",
    "    df['primary_key'] = [f\"{row['docid']}_{row['word_id']}\" for idx, row in df.iterrows()]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9332c8-cd3d-4284-bf36-b2df27c73d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30150/4294371539.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['word_id'] = df_wordidx\n",
      "/tmp/ipykernel_30150/4294371539.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['primary_key'] = [f\"{row['docid']}_{row['word_id']}\" for idx, row in df.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "df_data_document_context = make_word_boundaries(df_data_document_context)\n",
    "# df_data_context = make_word_boundaries(df_data_context)\n",
    "# df_data_context.head()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10be332-dd7c-4517-af6f-37e99e83c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual/Nonfactual split 6966 141\n"
     ]
    }
   ],
   "source": [
    "def get_sample(df):\n",
    "    df_sample_nonfactual = df[df['label'] == 1]\n",
    "    print('Factual/Nonfactual split', len(df[df['label'] == 0]), len(df_sample_nonfactual))\n",
    "    df_sample_factual = df[df['label'] == 0].sample(len(df_sample_nonfactual))\n",
    "    df_sample = pd.concat([df_sample_nonfactual, df_sample_factual\n",
    "                                           ])\n",
    "    return df_sample\n",
    "    \n",
    "df_sample_document_context = get_sample(df_data_document_context)\n",
    "# df_sample_context = get_sample(df_data_context)\n",
    "# df_sample_context = df_sample_context[df_sample_context['"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a7ddbf-1604-454c-9233-e7019ca56d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "sns.histplot(df_data_document_context[df_data_document_context['label'] == 0]['layer_prob32'],  \n",
    "             label='Factual Class',\n",
    "            ax = axes[0],\n",
    "            color='green')\n",
    "# sns.histplot(df_sample_document_context[df_sample_document_context['label'] == 1]['layer_prob32'],  \n",
    "#              label='Nonfactual Class',\n",
    "#             ax = axes[1],\n",
    "#             color='red')\n",
    "\n",
    "# sns.distplot(df_sample_document_context[df_sample_document_context['label'] == 1]['layer_prob32'], \n",
    "#              kde=True, \n",
    "#              label='Factual Class',\n",
    "#             ax = axes[1],\n",
    "#             kde_kws={'bw_method': 0.2, 'common_norm': True})\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(0, 1)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6c4d74-cbb6-4bcb-a559-5b7c3551810f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3033602285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    for unique_docid in\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for unique_docid in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dda8b4-3dd2-4381-89e0-3a63ca70d4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (probe)",
   "language": "python",
   "name": "probe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
